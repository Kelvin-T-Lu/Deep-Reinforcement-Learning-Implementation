{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "authors": [
      {
        "name": "Tejaswin Parthasarathy"
      }
    ],
    "celltoolbar": "Tags",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.1"
    },
    "gpuClass": "premium"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nwzLpDNa2Jpe"
      },
      "source": [
        "# Deep Q-Learning "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eT9-9fVc2Jpk",
        "tags": [
          "noshow"
        ]
      },
      "source": [
        "Install dependencies for AI gym to run properly (shouldn't take more than a minute). If running on google cloud or running locally, only need to run once. Colab may require installing everytime the vm shuts down."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X1cKbR-G2Jpl",
        "tags": [
          "noshow"
        ],
        "outputId": "35e6615d-3e94-4db6-c7cc-fbc5e321b9ce"
      },
      "source": [
        "!pip3 install gym pyvirtualdisplay\n",
        "!sudo apt-get install -y xvfb python-opengl ffmpeg"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gym in /usr/local/lib/python3.9/dist-packages (0.25.2)\n",
            "Collecting pyvirtualdisplay\n",
            "  Downloading PyVirtualDisplay-3.0-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: importlib-metadata>=4.8.0 in /usr/local/lib/python3.9/dist-packages (from gym) (6.4.1)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.9/dist-packages (from gym) (1.22.4)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.9/dist-packages (from gym) (2.2.1)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.9/dist-packages (from gym) (0.0.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.9/dist-packages (from importlib-metadata>=4.8.0->gym) (3.15.0)\n",
            "Installing collected packages: pyvirtualdisplay\n",
            "Successfully installed pyvirtualdisplay-3.0\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:4.2.7-0ubuntu0.1).\n",
            "The following additional packages will be installed:\n",
            "  freeglut3 libfontenc1 libpython2-stdlib libxfont2 libxkbfile1 python2\n",
            "  python2-minimal x11-xkb-utils xfonts-base xfonts-encodings xfonts-utils\n",
            "  xserver-common\n",
            "Suggested packages:\n",
            "  python-tk python-numpy libgle3 python2-doc\n",
            "The following NEW packages will be installed:\n",
            "  freeglut3 libfontenc1 libpython2-stdlib libxfont2 libxkbfile1 python-opengl\n",
            "  python2 python2-minimal x11-xkb-utils xfonts-base xfonts-encodings\n",
            "  xfonts-utils xserver-common xvfb\n",
            "0 upgraded, 14 newly installed, 0 to remove and 24 not upgraded.\n",
            "Need to get 8,318 kB of archives.\n",
            "After this operation, 18.0 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu focal/universe amd64 python2-minimal amd64 2.7.17-2ubuntu4 [27.5 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu focal/universe amd64 libpython2-stdlib amd64 2.7.17-2ubuntu4 [7,072 B]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu focal/universe amd64 python2 amd64 2.7.17-2ubuntu4 [26.5 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu focal/universe amd64 freeglut3 amd64 2.8.1-3 [73.6 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu focal/main amd64 libfontenc1 amd64 1:1.1.4-0ubuntu1 [14.0 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu focal/main amd64 libxfont2 amd64 1:2.0.3-1 [91.7 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu focal/main amd64 libxkbfile1 amd64 1:1.1.0-1 [65.3 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu focal/universe amd64 python-opengl all 3.1.0+dfsg-2build1 [486 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu focal/main amd64 x11-xkb-utils amd64 7.7+5 [158 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu focal/main amd64 xfonts-encodings all 1:1.0.5-0ubuntu1 [573 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu focal/main amd64 xfonts-utils amd64 1:7.7+6 [91.5 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu focal/main amd64 xfonts-base all 1:1.0.5 [5,896 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 xserver-common all 2:1.20.13-1ubuntu1~20.04.8 [27.2 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 xvfb amd64 2:1.20.13-1ubuntu1~20.04.8 [780 kB]\n",
            "Fetched 8,318 kB in 5s (1,584 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 14.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package python2-minimal.\n",
            "(Reading database ... 122352 files and directories currently installed.)\n",
            "Preparing to unpack .../python2-minimal_2.7.17-2ubuntu4_amd64.deb ...\n",
            "Unpacking python2-minimal (2.7.17-2ubuntu4) ...\n",
            "Selecting previously unselected package libpython2-stdlib:amd64.\n",
            "Preparing to unpack .../libpython2-stdlib_2.7.17-2ubuntu4_amd64.deb ...\n",
            "Unpacking libpython2-stdlib:amd64 (2.7.17-2ubuntu4) ...\n",
            "Setting up python2-minimal (2.7.17-2ubuntu4) ...\n",
            "Selecting previously unselected package python2.\n",
            "(Reading database ... 122381 files and directories currently installed.)\n",
            "Preparing to unpack .../00-python2_2.7.17-2ubuntu4_amd64.deb ...\n",
            "Unpacking python2 (2.7.17-2ubuntu4) ...\n",
            "Selecting previously unselected package freeglut3:amd64.\n",
            "Preparing to unpack .../01-freeglut3_2.8.1-3_amd64.deb ...\n",
            "Unpacking freeglut3:amd64 (2.8.1-3) ...\n",
            "Selecting previously unselected package libfontenc1:amd64.\n",
            "Preparing to unpack .../02-libfontenc1_1%3a1.1.4-0ubuntu1_amd64.deb ...\n",
            "Unpacking libfontenc1:amd64 (1:1.1.4-0ubuntu1) ...\n",
            "Selecting previously unselected package libxfont2:amd64.\n",
            "Preparing to unpack .../03-libxfont2_1%3a2.0.3-1_amd64.deb ...\n",
            "Unpacking libxfont2:amd64 (1:2.0.3-1) ...\n",
            "Selecting previously unselected package libxkbfile1:amd64.\n",
            "Preparing to unpack .../04-libxkbfile1_1%3a1.1.0-1_amd64.deb ...\n",
            "Unpacking libxkbfile1:amd64 (1:1.1.0-1) ...\n",
            "Selecting previously unselected package python-opengl.\n",
            "Preparing to unpack .../05-python-opengl_3.1.0+dfsg-2build1_all.deb ...\n",
            "Unpacking python-opengl (3.1.0+dfsg-2build1) ...\n",
            "Selecting previously unselected package x11-xkb-utils.\n",
            "Preparing to unpack .../06-x11-xkb-utils_7.7+5_amd64.deb ...\n",
            "Unpacking x11-xkb-utils (7.7+5) ...\n",
            "Selecting previously unselected package xfonts-encodings.\n",
            "Preparing to unpack .../07-xfonts-encodings_1%3a1.0.5-0ubuntu1_all.deb ...\n",
            "Unpacking xfonts-encodings (1:1.0.5-0ubuntu1) ...\n",
            "Selecting previously unselected package xfonts-utils.\n",
            "Preparing to unpack .../08-xfonts-utils_1%3a7.7+6_amd64.deb ...\n",
            "Unpacking xfonts-utils (1:7.7+6) ...\n",
            "Selecting previously unselected package xfonts-base.\n",
            "Preparing to unpack .../09-xfonts-base_1%3a1.0.5_all.deb ...\n",
            "Unpacking xfonts-base (1:1.0.5) ...\n",
            "Selecting previously unselected package xserver-common.\n",
            "Preparing to unpack .../10-xserver-common_2%3a1.20.13-1ubuntu1~20.04.8_all.deb ...\n",
            "Unpacking xserver-common (2:1.20.13-1ubuntu1~20.04.8) ...\n",
            "Selecting previously unselected package xvfb.\n",
            "Preparing to unpack .../11-xvfb_2%3a1.20.13-1ubuntu1~20.04.8_amd64.deb ...\n",
            "Unpacking xvfb (2:1.20.13-1ubuntu1~20.04.8) ...\n",
            "Setting up freeglut3:amd64 (2.8.1-3) ...\n",
            "Setting up libpython2-stdlib:amd64 (2.7.17-2ubuntu4) ...\n",
            "Setting up python2 (2.7.17-2ubuntu4) ...\n",
            "Setting up libfontenc1:amd64 (1:1.1.4-0ubuntu1) ...\n",
            "Setting up xfonts-encodings (1:1.0.5-0ubuntu1) ...\n",
            "Setting up libxkbfile1:amd64 (1:1.1.0-1) ...\n",
            "Setting up libxfont2:amd64 (1:2.0.3-1) ...\n",
            "Setting up python-opengl (3.1.0+dfsg-2build1) ...\n",
            "Setting up x11-xkb-utils (7.7+5) ...\n",
            "Setting up xfonts-utils (1:7.7+6) ...\n",
            "Setting up xfonts-base (1:1.0.5) ...\n",
            "Setting up xserver-common (2:1.20.13-1ubuntu1~20.04.8) ...\n",
            "Setting up xvfb (2:1.20.13-1ubuntu1~20.04.8) ...\n",
            "Processing triggers for man-db (2.9.1-1) ...\n",
            "Processing triggers for fontconfig (2.13.1-2ubuntu3) ...\n",
            "Processing triggers for libc-bin (2.31-0ubuntu9.9) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "FsVUH70E2Jpm",
        "tags": [
          "noshow"
        ],
        "outputId": "e9159130-a66e-4fd9-9db1-58f294a8fb15"
      },
      "source": [
        "!pip3 install --upgrade setuptools --user\n",
        "!pip3 install ez_setup \n",
        "!pip3 install gym[atari] \n",
        "!pip3 install autorom[accept-rom-license]"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (67.6.1)\n",
            "Collecting setuptools\n",
            "  Downloading setuptools-67.7.0-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m52.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: setuptools\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.34.0 requires jedi>=0.16, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed setuptools-67.7.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting ez_setup\n",
            "  Downloading ez_setup-0.9.tar.gz (6.6 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: ez_setup\n",
            "  Building wheel for ez_setup (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ez_setup: filename=ez_setup-0.9-py3-none-any.whl size=11012 sha256=95df4cccb0ee41b6da442c3234d9fd726f5c2bd59e77d2e8e658c777c08ccdd5\n",
            "  Stored in directory: /root/.cache/pip/wheels/d7/39/49/e7ce9ce92f074adc6f755a0cc05992407730e14d94ce3f9554\n",
            "Successfully built ez_setup\n",
            "Installing collected packages: ez_setup\n",
            "Successfully installed ez_setup-0.9\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gym[atari] in /usr/local/lib/python3.9/dist-packages (0.25.2)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.9/dist-packages (from gym[atari]) (0.0.8)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.9/dist-packages (from gym[atari]) (1.22.4)\n",
            "Requirement already satisfied: importlib-metadata>=4.8.0 in /usr/local/lib/python3.9/dist-packages (from gym[atari]) (6.4.1)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.9/dist-packages (from gym[atari]) (2.2.1)\n",
            "Collecting ale-py~=0.7.5\n",
            "  Downloading ale_py-0.7.5-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m68.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: importlib-resources in /usr/local/lib/python3.9/dist-packages (from ale-py~=0.7.5->gym[atari]) (5.12.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.9/dist-packages (from importlib-metadata>=4.8.0->gym[atari]) (3.15.0)\n",
            "Installing collected packages: ale-py\n",
            "Successfully installed ale-py-0.7.5\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "gym"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting autorom[accept-rom-license]\n",
            "  Downloading AutoROM-0.6.1-py3-none-any.whl (9.4 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from autorom[accept-rom-license]) (2.27.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.9/dist-packages (from autorom[accept-rom-license]) (8.1.3)\n",
            "Collecting AutoROM.accept-rom-license\n",
            "  Downloading AutoROM.accept-rom-license-0.6.1.tar.gz (434 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m434.7/434.7 kB\u001b[0m \u001b[31m32.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->autorom[accept-rom-license]) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->autorom[accept-rom-license]) (2.0.12)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->autorom[accept-rom-license]) (1.26.15)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->autorom[accept-rom-license]) (3.4)\n",
            "Building wheels for collected packages: AutoROM.accept-rom-license\n",
            "  Building wheel for AutoROM.accept-rom-license (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for AutoROM.accept-rom-license: filename=AutoROM.accept_rom_license-0.6.1-py3-none-any.whl size=446676 sha256=cc3e7e92f2d3133d09e4c04ca7aca831ca1472434006f6e4489ab96f76a570e8\n",
            "  Stored in directory: /root/.cache/pip/wheels/b1/1f/f7/2da07cf4f81ea264bdaf043028749d88fe0c2227134a22cf80\n",
            "Successfully built AutoROM.accept-rom-license\n",
            "Installing collected packages: AutoROM.accept-rom-license, autorom\n",
            "Successfully installed AutoROM.accept-rom-license-0.6.1 autorom-0.6.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z2Mq7JV42S2p",
        "tags": [
          "noshow"
        ],
        "outputId": "802c9bd0-cbc1-43c8-aa68-2274619daaad"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QbOX7kGY2U1m",
        "tags": [
          "noshow"
        ]
      },
      "source": [
        "import os\n",
        "\n",
        "os.chdir(\"/content/gdrive/MyDrive/DRL_747_Clone\")"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CvvYZnOG2Jpm"
      },
      "source": [
        "For this assignment we will implement the Deep Q-Learning algorithm with Experience Replay as described in breakthrough paper __\"Playing Atari with Deep Reinforcement Learning\"__. We will train an agent to play the famous game of __Breakout__."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BFZR87Ff2Jpm",
        "tags": [
          "noshow"
        ]
      },
      "source": [
        "%matplotlib inline\n",
        "\n",
        "import sys\n",
        "import gym\n",
        "import torch\n",
        "import pylab\n",
        "import random\n",
        "import numpy as np\n",
        "from collections import deque\n",
        "from datetime import datetime\n",
        "from copy import deepcopy\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "from model import DQN\n",
        "from utils import find_max_lives, check_live, get_frame, get_init_state\n",
        "from config import *\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%load_ext autoreload\n",
        "%autoreload 1\n",
        "%aimport agent\n",
        "%aimport agent_double\n",
        "%aimport config"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KoqzqqIW2Jpn"
      },
      "source": [
        "## Understanding the environment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bn32XdN-2Jpn"
      },
      "source": [
        "In the following cell, we initialize our game of __Breakout__ and you can see how the environment looks like. For further documentation of the of the environment refer to https://gym.openai.com/envs. \n",
        "\n",
        "In breakout, we will use 3 actions \"fire\", \"left\", and \"right\". \"fire\" is only used to reset the game when a life is lost, \"left\" moves the agent left and \"right\" moves the agent right."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rJzZH0QA2Jpn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328
        },
        "outputId": "02f8ca58-4c58-4bfb-83c3-6180f9369336"
      },
      "source": [
        "env = gym.make('BreakoutDeterministic-v4')\n",
        "state = env.reset()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameNotFound",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameNotFound\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-38edab2208ab>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0menv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgym\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'BreakoutDeterministic-v4'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/gym/envs/registration.py\u001b[0m in \u001b[0;36mmake\u001b[0;34m(id, max_episode_steps, autoreset, new_step_api, disable_env_checker, **kwargs)\u001b[0m\n\u001b[1;32m    605\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    606\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mspec_\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 607\u001b[0;31m             \u001b[0m_check_version_exists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mversion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    608\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"No registered env with id: {id}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/gym/envs/registration.py\u001b[0m in \u001b[0;36m_check_version_exists\u001b[0;34m(ns, name, version)\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m     \u001b[0m_check_name_exists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m         \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/gym/envs/registration.py\u001b[0m in \u001b[0;36m_check_name_exists\u001b[0;34m(ns, name)\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0msuggestion_msg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"Did you mean: `{suggestion[0]}`?\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0msuggestion\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m     raise error.NameNotFound(\n\u001b[0m\u001b[1;32m    213\u001b[0m         \u001b[0;34mf\"Environment {name} doesn't exist{namespace_msg}. {suggestion_msg}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m     )\n",
            "\u001b[0;31mNameNotFound\u001b[0m: Environment BreakoutDeterministic doesn't exist. "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mNt6Khmd2Jpo",
        "tags": [
          "noshow"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "outputId": "8af00085-c663-4b18-d5ae-0f9f52a2af8c"
      },
      "source": [
        "number_lives = find_max_lives(env)\n",
        "state_size = env.observation_space.shape\n",
        "action_size = 3 #fire, left, and right"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-56b2b7f7e038>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnumber_lives\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_max_lives\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mstate_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobservation_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0maction_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m \u001b[0;31m#fire, left, and right\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'env' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uKcoGYLr2Jpo"
      },
      "source": [
        "## Creating a DQN Agent"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TIBCLXtP2Jpo"
      },
      "source": [
        "Here we create a DQN Agent. This agent is defined in the __agent.py__. The corresponding neural network is defined in the __model.py__. Once you've created a working DQN agent, use the code in agent.py to create a double DQN agent in __agent_double.py__. Set the flag \"double_dqn\" to True to train the double DQN agent.\n",
        "\n",
        "__Evaluation Reward__ : The average reward received in the past 100 episodes/games.\n",
        "\n",
        "__Frame__ : Number of frames processed in total.\n",
        "\n",
        "__Memory Size__ : The current size of the replay memory."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7be4RHK42Jpo",
        "tags": [
          "noshow"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e7a9bb76-4324-42fa-9708-5b82f823188b"
      },
      "source": [
        "double_dqn = False # set to True if using double DQN agent\n",
        "\n",
        "if double_dqn:\n",
        "    from agent_double import Agent\n",
        "    model_type = \"double_dqn\"\n",
        "else:\n",
        "    from agent import Agent\n",
        "    model_type = \"deep_qn\"\n",
        "\n",
        "agent = Agent(action_size)\n",
        "evaluation_reward = deque(maxlen=evaluation_reward_length)\n",
        "frame = 0\n",
        "memory_size = 0"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WZH73jUz2Jpp"
      },
      "source": [
        "### Main Training Loop"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z_YEi6dT2Jpp",
        "tags": [
          "noshow"
        ]
      },
      "source": [
        "In this training loop, we do not render the screen because it slows down training signficantly. To watch the agent play the game, run the code in next section \"Visualize Agent Performance\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SYX6oHMn4YGd"
      },
      "source": [
        "Here, we do not report the entire training history. For this history, please see the attached notebook. Rather, we only showcase the final plots from training both vanilla DQN and DDQN networks for the Breakout task."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Td6XJktI2Jpp",
        "scrolled": true,
        "tags": [
          "noshow"
        ],
        "outputId": "7f10952d-7346-41dc-ee54-fa103eba6a69"
      },
      "source": [
        "rewards, episodes = [], []\n",
        "best_eval_reward = 0\n",
        "for e in range(EPISODES):\n",
        "    done = False\n",
        "    score = 0\n",
        "\n",
        "    history = np.zeros([5, 84, 84], dtype=np.uint8)\n",
        "    step = 0\n",
        "    d = False\n",
        "    state = env.reset()\n",
        "    next_state = state\n",
        "    life = number_lives\n",
        "\n",
        "    get_init_state(history, state)\n",
        "\n",
        "    while not done:\n",
        "        step += 1\n",
        "        frame += 1\n",
        "\n",
        "        # Perform a fire action if ball is no longer on screen to continue onto next life\n",
        "        if step > 1 and len(np.unique(next_state[:189] == state[:189])) < 2:\n",
        "            action = 0\n",
        "        else:\n",
        "            action = agent.get_action(np.float32(history[:4, :, :]) / 255.)\n",
        "        state = next_state\n",
        "        next_state, reward, done, info = env.step(action + 1)\n",
        "        \n",
        "        frame_next_state = get_frame(next_state)\n",
        "        history[4, :, :] = frame_next_state\n",
        "        terminal_state = check_live(life, info['lives'])\n",
        "\n",
        "        life = info['lives']\n",
        "        r = np.clip(reward, -1, 1) \n",
        "        r = reward\n",
        "\n",
        "        # Store the transition in memory \n",
        "        agent.memory.push(deepcopy(frame_next_state), action, r, terminal_state)\n",
        "        # Start training after random sample generation\n",
        "        if(frame >= train_frame):\n",
        "            # print(train_frame, frame)\n",
        "            agent.train_policy_net(frame)\n",
        "            # Update the target network only for Double DQN only\n",
        "            if double_dqn and (frame % update_target_network_frequency)== 0:\n",
        "                agent.update_target_net()\n",
        "        score += reward\n",
        "        history[:4, :, :] = history[1:, :, :]\n",
        "            \n",
        "        if done:\n",
        "            evaluation_reward.append(score)\n",
        "            rewards.append(np.mean(evaluation_reward))\n",
        "            episodes.append(e)\n",
        "            pylab.plot(episodes, rewards, 'b')\n",
        "            pylab.xlabel('Episodes')\n",
        "            pylab.ylabel('Rewards') \n",
        "            pylab.title('Episodes vs Reward')\n",
        "            pylab.savefig(f\"./save_graph/breakout_{model_type}.png\") # save graph for training visualization\n",
        "            \n",
        "            # every episode, plot the play time\n",
        "            print(\"episode:\", e, \"  score:\", score, \"  memory length:\",\n",
        "                  len(agent.memory), \"  epsilon:\", agent.epsilon, \"   steps:\", step,\n",
        "                  \"   lr:\", agent.optimizer.param_groups[0]['lr'], \"    evaluation reward:\", np.mean(evaluation_reward))\n",
        "\n",
        "            # if the mean of scores of last 100 episode is bigger than 5 save model\n",
        "            ### Change this save condition to whatever you prefer ###\n",
        "            if np.mean(evaluation_reward) > 5 and np.mean(evaluation_reward) > best_eval_reward:\n",
        "                torch.save(agent.policy_net.state_dict(), f\"./save_model/breakout_{model_type}.pth\")\n",
        "                best_eval_reward = np.mean(evaluation_reward)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "episode: 0   score: 0.0   memory length: 124   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 0.0\n",
            "episode: 1   score: 0.0   memory length: 248   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 0.0\n",
            "episode: 2   score: 1.0   memory length: 418   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 0.3333333333333333\n",
            "episode: 3   score: 4.0   memory length: 680   epsilon: 1.0    steps: 262    lr: 0.0001     evaluation reward: 1.25\n",
            "episode: 4   score: 1.0   memory length: 852   epsilon: 1.0    steps: 172    lr: 0.0001     evaluation reward: 1.2\n",
            "episode: 5   score: 0.0   memory length: 976   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.0\n",
            "episode: 6   score: 0.0   memory length: 1100   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 0.8571428571428571\n",
            "episode: 7   score: 2.0   memory length: 1319   epsilon: 1.0    steps: 219    lr: 0.0001     evaluation reward: 1.0\n",
            "episode: 8   score: 3.0   memory length: 1566   epsilon: 1.0    steps: 247    lr: 0.0001     evaluation reward: 1.2222222222222223\n",
            "episode: 9   score: 0.0   memory length: 1689   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.1\n",
            "episode: 10   score: 2.0   memory length: 1888   epsilon: 1.0    steps: 199    lr: 0.0001     evaluation reward: 1.1818181818181819\n",
            "episode: 11   score: 0.0   memory length: 2012   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.0833333333333333\n",
            "episode: 12   score: 2.0   memory length: 2211   epsilon: 1.0    steps: 199    lr: 0.0001     evaluation reward: 1.1538461538461537\n",
            "episode: 13   score: 0.0   memory length: 2335   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.0714285714285714\n",
            "episode: 14   score: 0.0   memory length: 2458   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.0\n",
            "episode: 15   score: 1.0   memory length: 2610   epsilon: 1.0    steps: 152    lr: 0.0001     evaluation reward: 1.0\n",
            "episode: 16   score: 2.0   memory length: 2809   epsilon: 1.0    steps: 199    lr: 0.0001     evaluation reward: 1.0588235294117647\n",
            "episode: 17   score: 0.0   memory length: 2933   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.0\n",
            "episode: 18   score: 2.0   memory length: 3132   epsilon: 1.0    steps: 199    lr: 0.0001     evaluation reward: 1.0526315789473684\n",
            "episode: 19   score: 1.0   memory length: 3283   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.05\n",
            "episode: 20   score: 1.0   memory length: 3453   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.0476190476190477\n",
            "episode: 21   score: 2.0   memory length: 3652   epsilon: 1.0    steps: 199    lr: 0.0001     evaluation reward: 1.0909090909090908\n",
            "episode: 22   score: 2.0   memory length: 3851   epsilon: 1.0    steps: 199    lr: 0.0001     evaluation reward: 1.1304347826086956\n",
            "episode: 23   score: 1.0   memory length: 4020   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.125\n",
            "episode: 24   score: 2.0   memory length: 4218   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.16\n",
            "episode: 25   score: 0.0   memory length: 4342   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.1153846153846154\n",
            "episode: 26   score: 0.0   memory length: 4466   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.0740740740740742\n",
            "episode: 27   score: 0.0   memory length: 4589   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.0357142857142858\n",
            "episode: 28   score: 1.0   memory length: 4759   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.0344827586206897\n",
            "episode: 29   score: 0.0   memory length: 4883   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.0\n",
            "episode: 30   score: 0.0   memory length: 5007   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 0.967741935483871\n",
            "episode: 31   score: 1.0   memory length: 5159   epsilon: 1.0    steps: 152    lr: 0.0001     evaluation reward: 0.96875\n",
            "episode: 32   score: 0.0   memory length: 5283   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 0.9393939393939394\n",
            "episode: 33   score: 0.0   memory length: 5407   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 0.9117647058823529\n",
            "episode: 34   score: 2.0   memory length: 5608   epsilon: 1.0    steps: 201    lr: 0.0001     evaluation reward: 0.9428571428571428\n",
            "episode: 35   score: 0.0   memory length: 5732   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 0.9166666666666666\n",
            "episode: 36   score: 2.0   memory length: 5933   epsilon: 1.0    steps: 201    lr: 0.0001     evaluation reward: 0.9459459459459459\n",
            "episode: 37   score: 0.0   memory length: 6057   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 0.9210526315789473\n",
            "episode: 38   score: 4.0   memory length: 6336   epsilon: 1.0    steps: 279    lr: 0.0001     evaluation reward: 1.0\n",
            "episode: 39   score: 3.0   memory length: 6584   epsilon: 1.0    steps: 248    lr: 0.0001     evaluation reward: 1.05\n",
            "episode: 40   score: 0.0   memory length: 6708   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.024390243902439\n",
            "episode: 41   score: 1.0   memory length: 6859   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.0238095238095237\n",
            "episode: 42   score: 2.0   memory length: 7078   epsilon: 1.0    steps: 219    lr: 0.0001     evaluation reward: 1.0465116279069768\n",
            "episode: 43   score: 1.0   memory length: 7249   epsilon: 1.0    steps: 171    lr: 0.0001     evaluation reward: 1.0454545454545454\n",
            "episode: 44   score: 0.0   memory length: 7373   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.0222222222222221\n",
            "episode: 45   score: 3.0   memory length: 7638   epsilon: 1.0    steps: 265    lr: 0.0001     evaluation reward: 1.065217391304348\n",
            "episode: 46   score: 2.0   memory length: 7839   epsilon: 1.0    steps: 201    lr: 0.0001     evaluation reward: 1.0851063829787233\n",
            "episode: 47   score: 2.0   memory length: 8019   epsilon: 1.0    steps: 180    lr: 0.0001     evaluation reward: 1.1041666666666667\n",
            "episode: 48   score: 2.0   memory length: 8218   epsilon: 1.0    steps: 199    lr: 0.0001     evaluation reward: 1.1224489795918366\n",
            "episode: 49   score: 0.0   memory length: 8342   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.1\n",
            "episode: 50   score: 0.0   memory length: 8465   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.0784313725490196\n",
            "episode: 51   score: 0.0   memory length: 8588   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.0576923076923077\n",
            "episode: 52   score: 0.0   memory length: 8712   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.0377358490566038\n",
            "episode: 53   score: 2.0   memory length: 8911   epsilon: 1.0    steps: 199    lr: 0.0001     evaluation reward: 1.0555555555555556\n",
            "episode: 54   score: 1.0   memory length: 9062   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.0545454545454545\n",
            "episode: 55   score: 0.0   memory length: 9185   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.0357142857142858\n",
            "episode: 56   score: 1.0   memory length: 9357   epsilon: 1.0    steps: 172    lr: 0.0001     evaluation reward: 1.0350877192982457\n",
            "episode: 57   score: 2.0   memory length: 9574   epsilon: 1.0    steps: 217    lr: 0.0001     evaluation reward: 1.0517241379310345\n",
            "episode: 58   score: 1.0   memory length: 9747   epsilon: 1.0    steps: 173    lr: 0.0001     evaluation reward: 1.0508474576271187\n",
            "episode: 59   score: 1.0   memory length: 9900   epsilon: 1.0    steps: 153    lr: 0.0001     evaluation reward: 1.05\n",
            "episode: 60   score: 2.0   memory length: 10098   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.0655737704918034\n",
            "episode: 61   score: 1.0   memory length: 10268   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.064516129032258\n",
            "episode: 62   score: 3.0   memory length: 10496   epsilon: 1.0    steps: 228    lr: 0.0001     evaluation reward: 1.0952380952380953\n",
            "episode: 63   score: 3.0   memory length: 10765   epsilon: 1.0    steps: 269    lr: 0.0001     evaluation reward: 1.125\n",
            "episode: 64   score: 0.0   memory length: 10889   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.1076923076923078\n",
            "episode: 65   score: 4.0   memory length: 11184   epsilon: 1.0    steps: 295    lr: 0.0001     evaluation reward: 1.1515151515151516\n",
            "episode: 66   score: 2.0   memory length: 11403   epsilon: 1.0    steps: 219    lr: 0.0001     evaluation reward: 1.164179104477612\n",
            "episode: 67   score: 3.0   memory length: 11648   epsilon: 1.0    steps: 245    lr: 0.0001     evaluation reward: 1.1911764705882353\n",
            "episode: 68   score: 3.0   memory length: 11915   epsilon: 1.0    steps: 267    lr: 0.0001     evaluation reward: 1.2173913043478262\n",
            "episode: 69   score: 3.0   memory length: 12160   epsilon: 1.0    steps: 245    lr: 0.0001     evaluation reward: 1.2428571428571429\n",
            "episode: 70   score: 0.0   memory length: 12283   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.2253521126760563\n",
            "episode: 71   score: 4.0   memory length: 12541   epsilon: 1.0    steps: 258    lr: 0.0001     evaluation reward: 1.2638888888888888\n",
            "episode: 72   score: 0.0   memory length: 12664   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.2465753424657535\n",
            "episode: 73   score: 1.0   memory length: 12836   epsilon: 1.0    steps: 172    lr: 0.0001     evaluation reward: 1.2432432432432432\n",
            "episode: 74   score: 0.0   memory length: 12960   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.2266666666666666\n",
            "episode: 75   score: 1.0   memory length: 13129   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.2236842105263157\n",
            "episode: 76   score: 1.0   memory length: 13282   epsilon: 1.0    steps: 153    lr: 0.0001     evaluation reward: 1.2207792207792207\n",
            "episode: 77   score: 2.0   memory length: 13465   epsilon: 1.0    steps: 183    lr: 0.0001     evaluation reward: 1.2307692307692308\n",
            "episode: 78   score: 1.0   memory length: 13617   epsilon: 1.0    steps: 152    lr: 0.0001     evaluation reward: 1.2278481012658229\n",
            "episode: 79   score: 0.0   memory length: 13740   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.2125\n",
            "episode: 80   score: 3.0   memory length: 13985   epsilon: 1.0    steps: 245    lr: 0.0001     evaluation reward: 1.2345679012345678\n",
            "episode: 81   score: 1.0   memory length: 14154   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.2317073170731707\n",
            "episode: 82   score: 2.0   memory length: 14374   epsilon: 1.0    steps: 220    lr: 0.0001     evaluation reward: 1.2409638554216869\n",
            "episode: 83   score: 3.0   memory length: 14646   epsilon: 1.0    steps: 272    lr: 0.0001     evaluation reward: 1.2619047619047619\n",
            "episode: 84   score: 1.0   memory length: 14798   epsilon: 1.0    steps: 152    lr: 0.0001     evaluation reward: 1.2588235294117647\n",
            "episode: 85   score: 2.0   memory length: 15017   epsilon: 1.0    steps: 219    lr: 0.0001     evaluation reward: 1.2674418604651163\n",
            "episode: 86   score: 1.0   memory length: 15169   epsilon: 1.0    steps: 152    lr: 0.0001     evaluation reward: 1.264367816091954\n",
            "episode: 87   score: 3.0   memory length: 15395   epsilon: 1.0    steps: 226    lr: 0.0001     evaluation reward: 1.2840909090909092\n",
            "episode: 88   score: 1.0   memory length: 15565   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.2808988764044944\n",
            "episode: 89   score: 2.0   memory length: 15764   epsilon: 1.0    steps: 199    lr: 0.0001     evaluation reward: 1.288888888888889\n",
            "episode: 90   score: 4.0   memory length: 16081   epsilon: 1.0    steps: 317    lr: 0.0001     evaluation reward: 1.3186813186813187\n",
            "episode: 91   score: 2.0   memory length: 16280   epsilon: 1.0    steps: 199    lr: 0.0001     evaluation reward: 1.326086956521739\n",
            "episode: 92   score: 2.0   memory length: 16478   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.3333333333333333\n",
            "episode: 93   score: 2.0   memory length: 16677   epsilon: 1.0    steps: 199    lr: 0.0001     evaluation reward: 1.3404255319148937\n",
            "episode: 94   score: 3.0   memory length: 16906   epsilon: 1.0    steps: 229    lr: 0.0001     evaluation reward: 1.3578947368421053\n",
            "episode: 95   score: 1.0   memory length: 17077   epsilon: 1.0    steps: 171    lr: 0.0001     evaluation reward: 1.3541666666666667\n",
            "episode: 96   score: 0.0   memory length: 17200   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.3402061855670102\n",
            "episode: 97   score: 0.0   memory length: 17324   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.3265306122448979\n",
            "episode: 98   score: 2.0   memory length: 17525   epsilon: 1.0    steps: 201    lr: 0.0001     evaluation reward: 1.3333333333333333\n",
            "episode: 99   score: 0.0   memory length: 17648   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.32\n",
            "episode: 100   score: 3.0   memory length: 17875   epsilon: 1.0    steps: 227    lr: 0.0001     evaluation reward: 1.35\n",
            "episode: 101   score: 3.0   memory length: 18141   epsilon: 1.0    steps: 266    lr: 0.0001     evaluation reward: 1.38\n",
            "episode: 102   score: 2.0   memory length: 18339   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.39\n",
            "episode: 103   score: 1.0   memory length: 18511   epsilon: 1.0    steps: 172    lr: 0.0001     evaluation reward: 1.36\n",
            "episode: 104   score: 3.0   memory length: 18758   epsilon: 1.0    steps: 247    lr: 0.0001     evaluation reward: 1.38\n",
            "episode: 105   score: 2.0   memory length: 18957   epsilon: 1.0    steps: 199    lr: 0.0001     evaluation reward: 1.4\n",
            "episode: 106   score: 3.0   memory length: 19202   epsilon: 1.0    steps: 245    lr: 0.0001     evaluation reward: 1.43\n",
            "episode: 107   score: 1.0   memory length: 19353   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.42\n",
            "episode: 108   score: 2.0   memory length: 19570   epsilon: 1.0    steps: 217    lr: 0.0001     evaluation reward: 1.41\n",
            "episode: 109   score: 5.0   memory length: 19909   epsilon: 1.0    steps: 339    lr: 0.0001     evaluation reward: 1.46\n",
            "episode: 110   score: 1.0   memory length: 20079   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.45\n",
            "episode: 111   score: 5.0   memory length: 20404   epsilon: 1.0    steps: 325    lr: 0.0001     evaluation reward: 1.5\n",
            "episode: 112   score: 0.0   memory length: 20528   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.48\n",
            "episode: 113   score: 2.0   memory length: 20747   epsilon: 1.0    steps: 219    lr: 0.0001     evaluation reward: 1.5\n",
            "episode: 114   score: 2.0   memory length: 20966   epsilon: 1.0    steps: 219    lr: 0.0001     evaluation reward: 1.52\n",
            "episode: 115   score: 2.0   memory length: 21164   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.53\n",
            "episode: 116   score: 0.0   memory length: 21288   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.51\n",
            "episode: 117   score: 1.0   memory length: 21459   epsilon: 1.0    steps: 171    lr: 0.0001     evaluation reward: 1.52\n",
            "episode: 118   score: 1.0   memory length: 21611   epsilon: 1.0    steps: 152    lr: 0.0001     evaluation reward: 1.51\n",
            "episode: 119   score: 0.0   memory length: 21735   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.5\n",
            "episode: 120   score: 3.0   memory length: 21963   epsilon: 1.0    steps: 228    lr: 0.0001     evaluation reward: 1.52\n",
            "episode: 121   score: 1.0   memory length: 22114   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.51\n",
            "episode: 122   score: 1.0   memory length: 22284   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.5\n",
            "episode: 123   score: 2.0   memory length: 22501   epsilon: 1.0    steps: 217    lr: 0.0001     evaluation reward: 1.51\n",
            "episode: 124   score: 2.0   memory length: 22700   epsilon: 1.0    steps: 199    lr: 0.0001     evaluation reward: 1.51\n",
            "episode: 125   score: 1.0   memory length: 22852   epsilon: 1.0    steps: 152    lr: 0.0001     evaluation reward: 1.52\n",
            "episode: 126   score: 5.0   memory length: 23220   epsilon: 1.0    steps: 368    lr: 0.0001     evaluation reward: 1.57\n",
            "episode: 127   score: 3.0   memory length: 23470   epsilon: 1.0    steps: 250    lr: 0.0001     evaluation reward: 1.6\n",
            "episode: 128   score: 0.0   memory length: 23593   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.59\n",
            "episode: 129   score: 2.0   memory length: 23792   epsilon: 1.0    steps: 199    lr: 0.0001     evaluation reward: 1.61\n",
            "episode: 130   score: 3.0   memory length: 24021   epsilon: 1.0    steps: 229    lr: 0.0001     evaluation reward: 1.64\n",
            "episode: 131   score: 1.0   memory length: 24173   epsilon: 1.0    steps: 152    lr: 0.0001     evaluation reward: 1.64\n",
            "episode: 132   score: 3.0   memory length: 24403   epsilon: 1.0    steps: 230    lr: 0.0001     evaluation reward: 1.67\n",
            "episode: 133   score: 6.0   memory length: 24767   epsilon: 1.0    steps: 364    lr: 0.0001     evaluation reward: 1.73\n",
            "episode: 134   score: 0.0   memory length: 24891   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.71\n",
            "episode: 135   score: 3.0   memory length: 25161   epsilon: 1.0    steps: 270    lr: 0.0001     evaluation reward: 1.74\n",
            "episode: 136   score: 2.0   memory length: 25362   epsilon: 1.0    steps: 201    lr: 0.0001     evaluation reward: 1.74\n",
            "episode: 137   score: 2.0   memory length: 25560   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.76\n",
            "episode: 138   score: 7.0   memory length: 25952   epsilon: 1.0    steps: 392    lr: 0.0001     evaluation reward: 1.79\n",
            "episode: 139   score: 5.0   memory length: 26297   epsilon: 1.0    steps: 345    lr: 0.0001     evaluation reward: 1.81\n",
            "episode: 140   score: 0.0   memory length: 26420   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.81\n",
            "episode: 141   score: 2.0   memory length: 26618   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.82\n",
            "episode: 142   score: 2.0   memory length: 26840   epsilon: 1.0    steps: 222    lr: 0.0001     evaluation reward: 1.82\n",
            "episode: 143   score: 3.0   memory length: 27069   epsilon: 1.0    steps: 229    lr: 0.0001     evaluation reward: 1.84\n",
            "episode: 144   score: 3.0   memory length: 27297   epsilon: 1.0    steps: 228    lr: 0.0001     evaluation reward: 1.87\n",
            "episode: 145   score: 0.0   memory length: 27420   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.84\n",
            "episode: 146   score: 1.0   memory length: 27572   epsilon: 1.0    steps: 152    lr: 0.0001     evaluation reward: 1.83\n",
            "episode: 147   score: 1.0   memory length: 27723   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.82\n",
            "episode: 148   score: 2.0   memory length: 27941   epsilon: 1.0    steps: 218    lr: 0.0001     evaluation reward: 1.82\n",
            "episode: 149   score: 1.0   memory length: 28092   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.83\n",
            "episode: 150   score: 2.0   memory length: 28311   epsilon: 1.0    steps: 219    lr: 0.0001     evaluation reward: 1.85\n",
            "episode: 151   score: 1.0   memory length: 28481   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.86\n",
            "episode: 152   score: 0.0   memory length: 28604   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.86\n",
            "episode: 153   score: 0.0   memory length: 28728   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.84\n",
            "episode: 154   score: 2.0   memory length: 28927   epsilon: 1.0    steps: 199    lr: 0.0001     evaluation reward: 1.85\n",
            "episode: 155   score: 2.0   memory length: 29126   epsilon: 1.0    steps: 199    lr: 0.0001     evaluation reward: 1.87\n",
            "episode: 156   score: 3.0   memory length: 29353   epsilon: 1.0    steps: 227    lr: 0.0001     evaluation reward: 1.89\n",
            "episode: 157   score: 0.0   memory length: 29477   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.87\n",
            "episode: 158   score: 1.0   memory length: 29647   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.87\n",
            "episode: 159   score: 0.0   memory length: 29770   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.86\n",
            "episode: 160   score: 0.0   memory length: 29893   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.84\n",
            "episode: 161   score: 1.0   memory length: 30045   epsilon: 1.0    steps: 152    lr: 0.0001     evaluation reward: 1.84\n",
            "episode: 162   score: 1.0   memory length: 30217   epsilon: 1.0    steps: 172    lr: 0.0001     evaluation reward: 1.82\n",
            "episode: 163   score: 1.0   memory length: 30387   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.8\n",
            "episode: 164   score: 1.0   memory length: 30538   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.81\n",
            "episode: 165   score: 3.0   memory length: 30786   epsilon: 1.0    steps: 248    lr: 0.0001     evaluation reward: 1.8\n",
            "episode: 166   score: 2.0   memory length: 30984   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.8\n",
            "episode: 167   score: 1.0   memory length: 31157   epsilon: 1.0    steps: 173    lr: 0.0001     evaluation reward: 1.78\n",
            "episode: 168   score: 1.0   memory length: 31330   epsilon: 1.0    steps: 173    lr: 0.0001     evaluation reward: 1.76\n",
            "episode: 169   score: 3.0   memory length: 31599   epsilon: 1.0    steps: 269    lr: 0.0001     evaluation reward: 1.76\n",
            "episode: 170   score: 0.0   memory length: 31723   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.76\n",
            "episode: 171   score: 1.0   memory length: 31892   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.73\n",
            "episode: 172   score: 1.0   memory length: 32062   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.74\n",
            "episode: 173   score: 0.0   memory length: 32186   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.73\n",
            "episode: 174   score: 3.0   memory length: 32453   epsilon: 1.0    steps: 267    lr: 0.0001     evaluation reward: 1.76\n",
            "episode: 175   score: 0.0   memory length: 32576   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.75\n",
            "episode: 176   score: 0.0   memory length: 32700   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.74\n",
            "episode: 177   score: 0.0   memory length: 32824   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.72\n",
            "episode: 178   score: 1.0   memory length: 32994   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.72\n",
            "episode: 179   score: 1.0   memory length: 33145   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.73\n",
            "episode: 180   score: 0.0   memory length: 33269   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.7\n",
            "episode: 181   score: 1.0   memory length: 33442   epsilon: 1.0    steps: 173    lr: 0.0001     evaluation reward: 1.7\n",
            "episode: 182   score: 1.0   memory length: 33594   epsilon: 1.0    steps: 152    lr: 0.0001     evaluation reward: 1.69\n",
            "episode: 183   score: 2.0   memory length: 33792   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.68\n",
            "episode: 184   score: 0.0   memory length: 33916   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.67\n",
            "episode: 185   score: 3.0   memory length: 34161   epsilon: 1.0    steps: 245    lr: 0.0001     evaluation reward: 1.68\n",
            "episode: 186   score: 0.0   memory length: 34285   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.67\n",
            "episode: 187   score: 0.0   memory length: 34409   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.64\n",
            "episode: 188   score: 1.0   memory length: 34561   epsilon: 1.0    steps: 152    lr: 0.0001     evaluation reward: 1.64\n",
            "episode: 189   score: 2.0   memory length: 34777   epsilon: 1.0    steps: 216    lr: 0.0001     evaluation reward: 1.64\n",
            "episode: 190   score: 1.0   memory length: 34928   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.61\n",
            "episode: 191   score: 2.0   memory length: 35128   epsilon: 1.0    steps: 200    lr: 0.0001     evaluation reward: 1.61\n",
            "episode: 192   score: 0.0   memory length: 35251   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.59\n",
            "episode: 193   score: 1.0   memory length: 35403   epsilon: 1.0    steps: 152    lr: 0.0001     evaluation reward: 1.58\n",
            "episode: 194   score: 4.0   memory length: 35691   epsilon: 1.0    steps: 288    lr: 0.0001     evaluation reward: 1.59\n",
            "episode: 195   score: 3.0   memory length: 35918   epsilon: 1.0    steps: 227    lr: 0.0001     evaluation reward: 1.61\n",
            "episode: 196   score: 1.0   memory length: 36069   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.62\n",
            "episode: 197   score: 1.0   memory length: 36240   epsilon: 1.0    steps: 171    lr: 0.0001     evaluation reward: 1.63\n",
            "episode: 198   score: 0.0   memory length: 36364   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.61\n",
            "episode: 199   score: 0.0   memory length: 36488   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.61\n",
            "episode: 200   score: 2.0   memory length: 36705   epsilon: 1.0    steps: 217    lr: 0.0001     evaluation reward: 1.6\n",
            "episode: 201   score: 2.0   memory length: 36904   epsilon: 1.0    steps: 199    lr: 0.0001     evaluation reward: 1.59\n",
            "episode: 202   score: 0.0   memory length: 37028   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.57\n",
            "episode: 203   score: 3.0   memory length: 37255   epsilon: 1.0    steps: 227    lr: 0.0001     evaluation reward: 1.59\n",
            "episode: 204   score: 2.0   memory length: 37455   epsilon: 1.0    steps: 200    lr: 0.0001     evaluation reward: 1.58\n",
            "episode: 205   score: 1.0   memory length: 37625   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.57\n",
            "episode: 206   score: 2.0   memory length: 37847   epsilon: 1.0    steps: 222    lr: 0.0001     evaluation reward: 1.56\n",
            "episode: 207   score: 1.0   memory length: 37998   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.56\n",
            "episode: 208   score: 1.0   memory length: 38149   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.55\n",
            "episode: 209   score: 1.0   memory length: 38301   epsilon: 1.0    steps: 152    lr: 0.0001     evaluation reward: 1.51\n",
            "episode: 210   score: 3.0   memory length: 38548   epsilon: 1.0    steps: 247    lr: 0.0001     evaluation reward: 1.53\n",
            "episode: 211   score: 1.0   memory length: 38699   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.49\n",
            "episode: 212   score: 1.0   memory length: 38868   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.5\n",
            "episode: 213   score: 0.0   memory length: 38991   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.48\n",
            "episode: 214   score: 0.0   memory length: 39115   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.46\n",
            "episode: 215   score: 1.0   memory length: 39288   epsilon: 1.0    steps: 173    lr: 0.0001     evaluation reward: 1.45\n",
            "episode: 216   score: 0.0   memory length: 39412   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.45\n",
            "episode: 217   score: 2.0   memory length: 39630   epsilon: 1.0    steps: 218    lr: 0.0001     evaluation reward: 1.46\n",
            "episode: 218   score: 0.0   memory length: 39754   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.45\n",
            "episode: 219   score: 1.0   memory length: 39905   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.46\n",
            "episode: 220   score: 2.0   memory length: 40104   epsilon: 1.0    steps: 199    lr: 0.0001     evaluation reward: 1.45\n",
            "episode: 221   score: 0.0   memory length: 40228   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.44\n",
            "episode: 222   score: 1.0   memory length: 40400   epsilon: 1.0    steps: 172    lr: 0.0001     evaluation reward: 1.44\n",
            "episode: 223   score: 3.0   memory length: 40632   epsilon: 1.0    steps: 232    lr: 0.0001     evaluation reward: 1.45\n",
            "episode: 224   score: 1.0   memory length: 40804   epsilon: 1.0    steps: 172    lr: 0.0001     evaluation reward: 1.44\n",
            "episode: 225   score: 2.0   memory length: 41003   epsilon: 1.0    steps: 199    lr: 0.0001     evaluation reward: 1.45\n",
            "episode: 226   score: 0.0   memory length: 41127   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.4\n",
            "episode: 227   score: 2.0   memory length: 41326   epsilon: 1.0    steps: 199    lr: 0.0001     evaluation reward: 1.39\n",
            "episode: 228   score: 1.0   memory length: 41478   epsilon: 1.0    steps: 152    lr: 0.0001     evaluation reward: 1.4\n",
            "episode: 229   score: 3.0   memory length: 41746   epsilon: 1.0    steps: 268    lr: 0.0001     evaluation reward: 1.41\n",
            "episode: 230   score: 1.0   memory length: 41916   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.39\n",
            "episode: 231   score: 0.0   memory length: 42040   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.38\n",
            "episode: 232   score: 1.0   memory length: 42191   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.36\n",
            "episode: 233   score: 1.0   memory length: 42342   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.31\n",
            "episode: 234   score: 0.0   memory length: 42466   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.31\n",
            "episode: 235   score: 0.0   memory length: 42590   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.28\n",
            "episode: 236   score: 1.0   memory length: 42741   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.27\n",
            "episode: 237   score: 2.0   memory length: 42939   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.27\n",
            "episode: 238   score: 2.0   memory length: 43139   epsilon: 1.0    steps: 200    lr: 0.0001     evaluation reward: 1.22\n",
            "episode: 239   score: 2.0   memory length: 43338   epsilon: 1.0    steps: 199    lr: 0.0001     evaluation reward: 1.19\n",
            "episode: 240   score: 1.0   memory length: 43490   epsilon: 1.0    steps: 152    lr: 0.0001     evaluation reward: 1.2\n",
            "episode: 241   score: 4.0   memory length: 43765   epsilon: 1.0    steps: 275    lr: 0.0001     evaluation reward: 1.22\n",
            "episode: 242   score: 0.0   memory length: 43888   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.2\n",
            "episode: 243   score: 2.0   memory length: 44104   epsilon: 1.0    steps: 216    lr: 0.0001     evaluation reward: 1.19\n",
            "episode: 244   score: 2.0   memory length: 44303   epsilon: 1.0    steps: 199    lr: 0.0001     evaluation reward: 1.18\n",
            "episode: 245   score: 0.0   memory length: 44427   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.18\n",
            "episode: 246   score: 0.0   memory length: 44551   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.17\n",
            "episode: 247   score: 1.0   memory length: 44721   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.17\n",
            "episode: 248   score: 1.0   memory length: 44873   epsilon: 1.0    steps: 152    lr: 0.0001     evaluation reward: 1.16\n",
            "episode: 249   score: 0.0   memory length: 44997   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.15\n",
            "episode: 250   score: 2.0   memory length: 45195   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.15\n",
            "episode: 251   score: 4.0   memory length: 45453   epsilon: 1.0    steps: 258    lr: 0.0001     evaluation reward: 1.18\n",
            "episode: 252   score: 1.0   memory length: 45605   epsilon: 1.0    steps: 152    lr: 0.0001     evaluation reward: 1.19\n",
            "episode: 253   score: 3.0   memory length: 45872   epsilon: 1.0    steps: 267    lr: 0.0001     evaluation reward: 1.22\n",
            "episode: 254   score: 0.0   memory length: 45996   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.2\n",
            "episode: 255   score: 2.0   memory length: 46194   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.2\n",
            "episode: 256   score: 2.0   memory length: 46411   epsilon: 1.0    steps: 217    lr: 0.0001     evaluation reward: 1.19\n",
            "episode: 257   score: 0.0   memory length: 46534   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.19\n",
            "episode: 258   score: 1.0   memory length: 46705   epsilon: 1.0    steps: 171    lr: 0.0001     evaluation reward: 1.19\n",
            "episode: 259   score: 2.0   memory length: 46922   epsilon: 1.0    steps: 217    lr: 0.0001     evaluation reward: 1.21\n",
            "episode: 260   score: 2.0   memory length: 47140   epsilon: 1.0    steps: 218    lr: 0.0001     evaluation reward: 1.23\n",
            "episode: 261   score: 2.0   memory length: 47360   epsilon: 1.0    steps: 220    lr: 0.0001     evaluation reward: 1.24\n",
            "episode: 262   score: 1.0   memory length: 47511   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.24\n",
            "episode: 263   score: 1.0   memory length: 47681   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.24\n",
            "episode: 264   score: 0.0   memory length: 47804   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.23\n",
            "episode: 265   score: 1.0   memory length: 47973   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.21\n",
            "episode: 266   score: 2.0   memory length: 48174   epsilon: 1.0    steps: 201    lr: 0.0001     evaluation reward: 1.21\n",
            "episode: 267   score: 4.0   memory length: 48466   epsilon: 1.0    steps: 292    lr: 0.0001     evaluation reward: 1.24\n",
            "episode: 268   score: 2.0   memory length: 48665   epsilon: 1.0    steps: 199    lr: 0.0001     evaluation reward: 1.25\n",
            "episode: 269   score: 0.0   memory length: 48788   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.22\n",
            "episode: 270   score: 2.0   memory length: 48989   epsilon: 1.0    steps: 201    lr: 0.0001     evaluation reward: 1.24\n",
            "episode: 271   score: 2.0   memory length: 49188   epsilon: 1.0    steps: 199    lr: 0.0001     evaluation reward: 1.25\n",
            "episode: 272   score: 1.0   memory length: 49339   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.25\n",
            "episode: 273   score: 1.0   memory length: 49508   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.26\n",
            "episode: 274   score: 1.0   memory length: 49659   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.24\n",
            "episode: 275   score: 2.0   memory length: 49858   epsilon: 1.0    steps: 199    lr: 0.0001     evaluation reward: 1.26\n",
            "episode: 276   score: 0.0   memory length: 49981   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.26\n",
            "episode: 277   score: 0.0   memory length: 50105   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.26\n",
            "episode: 278   score: 0.0   memory length: 50229   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.25\n",
            "episode: 279   score: 0.0   memory length: 50353   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.24\n",
            "episode: 280   score: 0.0   memory length: 50476   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.24\n",
            "episode: 281   score: 0.0   memory length: 50599   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.23\n",
            "episode: 282   score: 2.0   memory length: 50820   epsilon: 1.0    steps: 221    lr: 0.0001     evaluation reward: 1.24\n",
            "episode: 283   score: 0.0   memory length: 50944   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.22\n",
            "episode: 284   score: 1.0   memory length: 51117   epsilon: 1.0    steps: 173    lr: 0.0001     evaluation reward: 1.23\n",
            "episode: 285   score: 0.0   memory length: 51240   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.2\n",
            "episode: 286   score: 0.0   memory length: 51364   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.2\n",
            "episode: 287   score: 3.0   memory length: 51610   epsilon: 1.0    steps: 246    lr: 0.0001     evaluation reward: 1.23\n",
            "episode: 288   score: 3.0   memory length: 51840   epsilon: 1.0    steps: 230    lr: 0.0001     evaluation reward: 1.25\n",
            "episode: 289   score: 1.0   memory length: 51991   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.24\n",
            "episode: 290   score: 0.0   memory length: 52115   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.23\n",
            "episode: 291   score: 0.0   memory length: 52239   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.21\n",
            "episode: 292   score: 0.0   memory length: 52362   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.21\n",
            "episode: 293   score: 4.0   memory length: 52679   epsilon: 1.0    steps: 317    lr: 0.0001     evaluation reward: 1.24\n",
            "episode: 294   score: 1.0   memory length: 52852   epsilon: 1.0    steps: 173    lr: 0.0001     evaluation reward: 1.21\n",
            "episode: 295   score: 9.0   memory length: 53243   epsilon: 1.0    steps: 391    lr: 0.0001     evaluation reward: 1.27\n",
            "episode: 296   score: 2.0   memory length: 53459   epsilon: 1.0    steps: 216    lr: 0.0001     evaluation reward: 1.28\n",
            "episode: 297   score: 0.0   memory length: 53583   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.27\n",
            "episode: 298   score: 1.0   memory length: 53753   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.28\n",
            "episode: 299   score: 1.0   memory length: 53923   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.29\n",
            "episode: 300   score: 3.0   memory length: 54174   epsilon: 1.0    steps: 251    lr: 0.0001     evaluation reward: 1.3\n",
            "episode: 301   score: 1.0   memory length: 54325   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.29\n",
            "episode: 302   score: 2.0   memory length: 54523   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.31\n",
            "episode: 303   score: 0.0   memory length: 54647   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.28\n",
            "episode: 304   score: 0.0   memory length: 54770   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.26\n",
            "episode: 305   score: 1.0   memory length: 54940   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.26\n",
            "episode: 306   score: 1.0   memory length: 55109   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.25\n",
            "episode: 307   score: 0.0   memory length: 55232   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.24\n",
            "episode: 308   score: 0.0   memory length: 55356   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.23\n",
            "episode: 309   score: 0.0   memory length: 55480   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.22\n",
            "episode: 310   score: 2.0   memory length: 55682   epsilon: 1.0    steps: 202    lr: 0.0001     evaluation reward: 1.21\n",
            "episode: 311   score: 2.0   memory length: 55881   epsilon: 1.0    steps: 199    lr: 0.0001     evaluation reward: 1.22\n",
            "episode: 312   score: 1.0   memory length: 56032   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.22\n",
            "episode: 313   score: 4.0   memory length: 56310   epsilon: 1.0    steps: 278    lr: 0.0001     evaluation reward: 1.26\n",
            "episode: 314   score: 2.0   memory length: 56528   epsilon: 1.0    steps: 218    lr: 0.0001     evaluation reward: 1.28\n",
            "episode: 315   score: 2.0   memory length: 56750   epsilon: 1.0    steps: 222    lr: 0.0001     evaluation reward: 1.29\n",
            "episode: 316   score: 2.0   memory length: 56970   epsilon: 1.0    steps: 220    lr: 0.0001     evaluation reward: 1.31\n",
            "episode: 317   score: 0.0   memory length: 57094   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.29\n",
            "episode: 318   score: 1.0   memory length: 57246   epsilon: 1.0    steps: 152    lr: 0.0001     evaluation reward: 1.3\n",
            "episode: 319   score: 2.0   memory length: 57463   epsilon: 1.0    steps: 217    lr: 0.0001     evaluation reward: 1.31\n",
            "episode: 320   score: 1.0   memory length: 57633   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.3\n",
            "episode: 321   score: 2.0   memory length: 57831   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.32\n",
            "episode: 322   score: 1.0   memory length: 57982   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.32\n",
            "episode: 323   score: 1.0   memory length: 58134   epsilon: 1.0    steps: 152    lr: 0.0001     evaluation reward: 1.3\n",
            "episode: 324   score: 2.0   memory length: 58333   epsilon: 1.0    steps: 199    lr: 0.0001     evaluation reward: 1.31\n",
            "episode: 325   score: 2.0   memory length: 58531   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.31\n",
            "episode: 326   score: 3.0   memory length: 58759   epsilon: 1.0    steps: 228    lr: 0.0001     evaluation reward: 1.34\n",
            "episode: 327   score: 2.0   memory length: 58957   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.34\n",
            "episode: 328   score: 1.0   memory length: 59127   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.34\n",
            "episode: 329   score: 3.0   memory length: 59376   epsilon: 1.0    steps: 249    lr: 0.0001     evaluation reward: 1.34\n",
            "episode: 330   score: 3.0   memory length: 59603   epsilon: 1.0    steps: 227    lr: 0.0001     evaluation reward: 1.36\n",
            "episode: 331   score: 2.0   memory length: 59824   epsilon: 1.0    steps: 221    lr: 0.0001     evaluation reward: 1.38\n",
            "episode: 332   score: 1.0   memory length: 59997   epsilon: 1.0    steps: 173    lr: 0.0001     evaluation reward: 1.38\n",
            "episode: 333   score: 4.0   memory length: 60297   epsilon: 1.0    steps: 300    lr: 0.0001     evaluation reward: 1.41\n",
            "episode: 334   score: 0.0   memory length: 60421   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.41\n",
            "episode: 335   score: 1.0   memory length: 60590   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.42\n",
            "episode: 336   score: 1.0   memory length: 60759   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.42\n",
            "episode: 337   score: 2.0   memory length: 60981   epsilon: 1.0    steps: 222    lr: 0.0001     evaluation reward: 1.42\n",
            "episode: 338   score: 1.0   memory length: 61151   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.41\n",
            "episode: 339   score: 2.0   memory length: 61331   epsilon: 1.0    steps: 180    lr: 0.0001     evaluation reward: 1.41\n",
            "episode: 340   score: 4.0   memory length: 61649   epsilon: 1.0    steps: 318    lr: 0.0001     evaluation reward: 1.44\n",
            "episode: 341   score: 0.0   memory length: 61773   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.4\n",
            "episode: 342   score: 2.0   memory length: 61993   epsilon: 1.0    steps: 220    lr: 0.0001     evaluation reward: 1.42\n",
            "episode: 343   score: 1.0   memory length: 62146   epsilon: 1.0    steps: 153    lr: 0.0001     evaluation reward: 1.41\n",
            "episode: 344   score: 0.0   memory length: 62269   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.39\n",
            "episode: 345   score: 1.0   memory length: 62440   epsilon: 1.0    steps: 171    lr: 0.0001     evaluation reward: 1.4\n",
            "episode: 346   score: 0.0   memory length: 62564   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.4\n",
            "episode: 347   score: 0.0   memory length: 62688   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.39\n",
            "episode: 348   score: 1.0   memory length: 62858   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.39\n",
            "episode: 349   score: 1.0   memory length: 63010   epsilon: 1.0    steps: 152    lr: 0.0001     evaluation reward: 1.4\n",
            "episode: 350   score: 2.0   memory length: 63229   epsilon: 1.0    steps: 219    lr: 0.0001     evaluation reward: 1.4\n",
            "episode: 351   score: 2.0   memory length: 63430   epsilon: 1.0    steps: 201    lr: 0.0001     evaluation reward: 1.38\n",
            "episode: 352   score: 1.0   memory length: 63581   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.38\n",
            "episode: 353   score: 2.0   memory length: 63800   epsilon: 1.0    steps: 219    lr: 0.0001     evaluation reward: 1.37\n",
            "episode: 354   score: 3.0   memory length: 64012   epsilon: 1.0    steps: 212    lr: 0.0001     evaluation reward: 1.4\n",
            "episode: 355   score: 3.0   memory length: 64259   epsilon: 1.0    steps: 247    lr: 0.0001     evaluation reward: 1.41\n",
            "episode: 356   score: 3.0   memory length: 64504   epsilon: 1.0    steps: 245    lr: 0.0001     evaluation reward: 1.42\n",
            "episode: 357   score: 2.0   memory length: 64703   epsilon: 1.0    steps: 199    lr: 0.0001     evaluation reward: 1.44\n",
            "episode: 358   score: 0.0   memory length: 64827   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.43\n",
            "episode: 359   score: 2.0   memory length: 65025   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.43\n",
            "episode: 360   score: 0.0   memory length: 65148   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.41\n",
            "episode: 361   score: 3.0   memory length: 65377   epsilon: 1.0    steps: 229    lr: 0.0001     evaluation reward: 1.42\n",
            "episode: 362   score: 0.0   memory length: 65501   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.41\n",
            "episode: 363   score: 1.0   memory length: 65674   epsilon: 1.0    steps: 173    lr: 0.0001     evaluation reward: 1.41\n",
            "episode: 364   score: 2.0   memory length: 65894   epsilon: 1.0    steps: 220    lr: 0.0001     evaluation reward: 1.43\n",
            "episode: 365   score: 2.0   memory length: 66114   epsilon: 1.0    steps: 220    lr: 0.0001     evaluation reward: 1.44\n",
            "episode: 366   score: 0.0   memory length: 66237   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.42\n",
            "episode: 367   score: 1.0   memory length: 66389   epsilon: 1.0    steps: 152    lr: 0.0001     evaluation reward: 1.39\n",
            "episode: 368   score: 1.0   memory length: 66559   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.38\n",
            "episode: 369   score: 2.0   memory length: 66743   epsilon: 1.0    steps: 184    lr: 0.0001     evaluation reward: 1.4\n",
            "episode: 370   score: 2.0   memory length: 66961   epsilon: 1.0    steps: 218    lr: 0.0001     evaluation reward: 1.4\n",
            "episode: 371   score: 0.0   memory length: 67085   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.38\n",
            "episode: 372   score: 2.0   memory length: 67302   epsilon: 1.0    steps: 217    lr: 0.0001     evaluation reward: 1.39\n",
            "episode: 373   score: 4.0   memory length: 67600   epsilon: 1.0    steps: 298    lr: 0.0001     evaluation reward: 1.42\n",
            "episode: 374   score: 3.0   memory length: 67829   epsilon: 1.0    steps: 229    lr: 0.0001     evaluation reward: 1.44\n",
            "episode: 375   score: 1.0   memory length: 67999   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.43\n",
            "episode: 376   score: 0.0   memory length: 68122   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.43\n",
            "episode: 377   score: 2.0   memory length: 68321   epsilon: 1.0    steps: 199    lr: 0.0001     evaluation reward: 1.45\n",
            "episode: 378   score: 0.0   memory length: 68445   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.45\n",
            "episode: 379   score: 2.0   memory length: 68644   epsilon: 1.0    steps: 199    lr: 0.0001     evaluation reward: 1.47\n",
            "episode: 380   score: 1.0   memory length: 68796   epsilon: 1.0    steps: 152    lr: 0.0001     evaluation reward: 1.48\n",
            "episode: 381   score: 1.0   memory length: 68966   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.49\n",
            "episode: 382   score: 1.0   memory length: 69120   epsilon: 1.0    steps: 154    lr: 0.0001     evaluation reward: 1.48\n",
            "episode: 383   score: 2.0   memory length: 69319   epsilon: 1.0    steps: 199    lr: 0.0001     evaluation reward: 1.5\n",
            "episode: 384   score: 0.0   memory length: 69443   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.49\n",
            "episode: 385   score: 2.0   memory length: 69663   epsilon: 1.0    steps: 220    lr: 0.0001     evaluation reward: 1.51\n",
            "episode: 386   score: 2.0   memory length: 69883   epsilon: 1.0    steps: 220    lr: 0.0001     evaluation reward: 1.53\n",
            "episode: 387   score: 0.0   memory length: 70006   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.5\n",
            "episode: 388   score: 0.0   memory length: 70130   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.47\n",
            "episode: 389   score: 0.0   memory length: 70254   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.46\n",
            "episode: 390   score: 1.0   memory length: 70407   epsilon: 1.0    steps: 153    lr: 0.0001     evaluation reward: 1.47\n",
            "episode: 391   score: 4.0   memory length: 70685   epsilon: 1.0    steps: 278    lr: 0.0001     evaluation reward: 1.51\n",
            "episode: 392   score: 0.0   memory length: 70809   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.51\n",
            "episode: 393   score: 0.0   memory length: 70932   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.47\n",
            "episode: 394   score: 0.0   memory length: 71056   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.46\n",
            "episode: 395   score: 2.0   memory length: 71277   epsilon: 1.0    steps: 221    lr: 0.0001     evaluation reward: 1.39\n",
            "episode: 396   score: 1.0   memory length: 71447   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.38\n",
            "episode: 397   score: 3.0   memory length: 71718   epsilon: 1.0    steps: 271    lr: 0.0001     evaluation reward: 1.41\n",
            "episode: 398   score: 0.0   memory length: 71841   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.4\n",
            "episode: 399   score: 7.0   memory length: 72254   epsilon: 1.0    steps: 413    lr: 0.0001     evaluation reward: 1.46\n",
            "episode: 400   score: 3.0   memory length: 72501   epsilon: 1.0    steps: 247    lr: 0.0001     evaluation reward: 1.46\n",
            "episode: 401   score: 3.0   memory length: 72746   epsilon: 1.0    steps: 245    lr: 0.0001     evaluation reward: 1.48\n",
            "episode: 402   score: 1.0   memory length: 72917   epsilon: 1.0    steps: 171    lr: 0.0001     evaluation reward: 1.47\n",
            "episode: 403   score: 0.0   memory length: 73041   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.47\n",
            "episode: 404   score: 1.0   memory length: 73212   epsilon: 1.0    steps: 171    lr: 0.0001     evaluation reward: 1.48\n",
            "episode: 405   score: 4.0   memory length: 73526   epsilon: 1.0    steps: 314    lr: 0.0001     evaluation reward: 1.51\n",
            "episode: 406   score: 2.0   memory length: 73746   epsilon: 1.0    steps: 220    lr: 0.0001     evaluation reward: 1.52\n",
            "episode: 407   score: 3.0   memory length: 73996   epsilon: 1.0    steps: 250    lr: 0.0001     evaluation reward: 1.55\n",
            "episode: 408   score: 1.0   memory length: 74169   epsilon: 1.0    steps: 173    lr: 0.0001     evaluation reward: 1.56\n",
            "episode: 409   score: 1.0   memory length: 74320   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.57\n",
            "episode: 410   score: 2.0   memory length: 74518   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.57\n",
            "episode: 411   score: 2.0   memory length: 74716   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.57\n",
            "episode: 412   score: 1.0   memory length: 74888   epsilon: 1.0    steps: 172    lr: 0.0001     evaluation reward: 1.57\n",
            "episode: 413   score: 2.0   memory length: 75111   epsilon: 1.0    steps: 223    lr: 0.0001     evaluation reward: 1.55\n",
            "episode: 414   score: 1.0   memory length: 75282   epsilon: 1.0    steps: 171    lr: 0.0001     evaluation reward: 1.54\n",
            "episode: 415   score: 0.0   memory length: 75405   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.52\n",
            "episode: 416   score: 2.0   memory length: 75603   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.52\n",
            "episode: 417   score: 0.0   memory length: 75726   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.52\n",
            "episode: 418   score: 1.0   memory length: 75878   epsilon: 1.0    steps: 152    lr: 0.0001     evaluation reward: 1.52\n",
            "episode: 419   score: 0.0   memory length: 76002   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.5\n",
            "episode: 420   score: 1.0   memory length: 76153   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.5\n",
            "episode: 421   score: 2.0   memory length: 76370   epsilon: 1.0    steps: 217    lr: 0.0001     evaluation reward: 1.5\n",
            "episode: 422   score: 0.0   memory length: 76493   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.49\n",
            "episode: 423   score: 4.0   memory length: 76792   epsilon: 1.0    steps: 299    lr: 0.0001     evaluation reward: 1.52\n",
            "episode: 424   score: 2.0   memory length: 76991   epsilon: 1.0    steps: 199    lr: 0.0001     evaluation reward: 1.52\n",
            "episode: 425   score: 3.0   memory length: 77239   epsilon: 1.0    steps: 248    lr: 0.0001     evaluation reward: 1.53\n",
            "episode: 426   score: 1.0   memory length: 77411   epsilon: 1.0    steps: 172    lr: 0.0001     evaluation reward: 1.51\n",
            "episode: 427   score: 0.0   memory length: 77535   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.49\n",
            "episode: 428   score: 2.0   memory length: 77752   epsilon: 1.0    steps: 217    lr: 0.0001     evaluation reward: 1.5\n",
            "episode: 429   score: 7.0   memory length: 78053   epsilon: 1.0    steps: 301    lr: 0.0001     evaluation reward: 1.54\n",
            "episode: 430   score: 3.0   memory length: 78321   epsilon: 1.0    steps: 268    lr: 0.0001     evaluation reward: 1.54\n",
            "episode: 431   score: 2.0   memory length: 78538   epsilon: 1.0    steps: 217    lr: 0.0001     evaluation reward: 1.54\n",
            "episode: 432   score: 3.0   memory length: 78809   epsilon: 1.0    steps: 271    lr: 0.0001     evaluation reward: 1.56\n",
            "episode: 433   score: 0.0   memory length: 78932   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.52\n",
            "episode: 434   score: 1.0   memory length: 79102   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.53\n",
            "episode: 435   score: 2.0   memory length: 79321   epsilon: 1.0    steps: 219    lr: 0.0001     evaluation reward: 1.54\n",
            "episode: 436   score: 1.0   memory length: 79494   epsilon: 1.0    steps: 173    lr: 0.0001     evaluation reward: 1.54\n",
            "episode: 437   score: 4.0   memory length: 79792   epsilon: 1.0    steps: 298    lr: 0.0001     evaluation reward: 1.56\n",
            "episode: 438   score: 2.0   memory length: 79992   epsilon: 1.0    steps: 200    lr: 0.0001     evaluation reward: 1.57\n",
            "episode: 439   score: 0.0   memory length: 80116   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.55\n",
            "episode: 440   score: 0.0   memory length: 80240   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.51\n",
            "episode: 441   score: 1.0   memory length: 80410   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.52\n",
            "episode: 442   score: 3.0   memory length: 80661   epsilon: 1.0    steps: 251    lr: 0.0001     evaluation reward: 1.53\n",
            "episode: 443   score: 2.0   memory length: 80844   epsilon: 1.0    steps: 183    lr: 0.0001     evaluation reward: 1.54\n",
            "episode: 444   score: 0.0   memory length: 80968   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.54\n",
            "episode: 445   score: 2.0   memory length: 81168   epsilon: 1.0    steps: 200    lr: 0.0001     evaluation reward: 1.55\n",
            "episode: 446   score: 0.0   memory length: 81291   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.55\n",
            "episode: 447   score: 1.0   memory length: 81462   epsilon: 1.0    steps: 171    lr: 0.0001     evaluation reward: 1.56\n",
            "episode: 448   score: 2.0   memory length: 81681   epsilon: 1.0    steps: 219    lr: 0.0001     evaluation reward: 1.57\n",
            "episode: 449   score: 1.0   memory length: 81833   epsilon: 1.0    steps: 152    lr: 0.0001     evaluation reward: 1.57\n",
            "episode: 450   score: 0.0   memory length: 81957   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.55\n",
            "episode: 451   score: 0.0   memory length: 82080   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.53\n",
            "episode: 452   score: 0.0   memory length: 82204   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.52\n",
            "episode: 453   score: 0.0   memory length: 82328   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.5\n",
            "episode: 454   score: 0.0   memory length: 82452   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.47\n",
            "episode: 455   score: 2.0   memory length: 82671   epsilon: 1.0    steps: 219    lr: 0.0001     evaluation reward: 1.46\n",
            "episode: 456   score: 0.0   memory length: 82795   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.43\n",
            "episode: 457   score: 3.0   memory length: 83022   epsilon: 1.0    steps: 227    lr: 0.0001     evaluation reward: 1.44\n",
            "episode: 458   score: 2.0   memory length: 83221   epsilon: 1.0    steps: 199    lr: 0.0001     evaluation reward: 1.46\n",
            "episode: 459   score: 1.0   memory length: 83391   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.45\n",
            "episode: 460   score: 5.0   memory length: 83732   epsilon: 1.0    steps: 341    lr: 0.0001     evaluation reward: 1.5\n",
            "episode: 461   score: 3.0   memory length: 83998   epsilon: 1.0    steps: 266    lr: 0.0001     evaluation reward: 1.5\n",
            "episode: 462   score: 2.0   memory length: 84216   epsilon: 1.0    steps: 218    lr: 0.0001     evaluation reward: 1.52\n",
            "episode: 463   score: 0.0   memory length: 84339   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.51\n",
            "episode: 464   score: 0.0   memory length: 84463   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.49\n",
            "episode: 465   score: 2.0   memory length: 84663   epsilon: 1.0    steps: 200    lr: 0.0001     evaluation reward: 1.49\n",
            "episode: 466   score: 2.0   memory length: 84879   epsilon: 1.0    steps: 216    lr: 0.0001     evaluation reward: 1.51\n",
            "episode: 467   score: 2.0   memory length: 85096   epsilon: 1.0    steps: 217    lr: 0.0001     evaluation reward: 1.52\n",
            "episode: 468   score: 0.0   memory length: 85220   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.51\n",
            "episode: 469   score: 2.0   memory length: 85439   epsilon: 1.0    steps: 219    lr: 0.0001     evaluation reward: 1.51\n",
            "episode: 470   score: 0.0   memory length: 85562   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.49\n",
            "episode: 471   score: 2.0   memory length: 85761   epsilon: 1.0    steps: 199    lr: 0.0001     evaluation reward: 1.51\n",
            "episode: 472   score: 1.0   memory length: 85932   epsilon: 1.0    steps: 171    lr: 0.0001     evaluation reward: 1.5\n",
            "episode: 473   score: 5.0   memory length: 86270   epsilon: 1.0    steps: 338    lr: 0.0001     evaluation reward: 1.51\n",
            "episode: 474   score: 2.0   memory length: 86469   epsilon: 1.0    steps: 199    lr: 0.0001     evaluation reward: 1.5\n",
            "episode: 475   score: 1.0   memory length: 86640   epsilon: 1.0    steps: 171    lr: 0.0001     evaluation reward: 1.5\n",
            "episode: 476   score: 0.0   memory length: 86764   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.5\n",
            "episode: 477   score: 0.0   memory length: 86888   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.48\n",
            "episode: 478   score: 1.0   memory length: 87059   epsilon: 1.0    steps: 171    lr: 0.0001     evaluation reward: 1.49\n",
            "episode: 479   score: 3.0   memory length: 87325   epsilon: 1.0    steps: 266    lr: 0.0001     evaluation reward: 1.5\n",
            "episode: 480   score: 1.0   memory length: 87495   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.5\n",
            "episode: 481   score: 1.0   memory length: 87664   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.5\n",
            "episode: 482   score: 0.0   memory length: 87787   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.49\n",
            "episode: 483   score: 0.0   memory length: 87911   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.47\n",
            "episode: 484   score: 1.0   memory length: 88081   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.48\n",
            "episode: 485   score: 1.0   memory length: 88251   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.47\n",
            "episode: 486   score: 2.0   memory length: 88470   epsilon: 1.0    steps: 219    lr: 0.0001     evaluation reward: 1.47\n",
            "episode: 487   score: 1.0   memory length: 88623   epsilon: 1.0    steps: 153    lr: 0.0001     evaluation reward: 1.48\n",
            "episode: 488   score: 0.0   memory length: 88747   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.48\n",
            "episode: 489   score: 0.0   memory length: 88871   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.48\n",
            "episode: 490   score: 3.0   memory length: 89120   epsilon: 1.0    steps: 249    lr: 0.0001     evaluation reward: 1.5\n",
            "episode: 491   score: 1.0   memory length: 89292   epsilon: 1.0    steps: 172    lr: 0.0001     evaluation reward: 1.47\n",
            "episode: 492   score: 4.0   memory length: 89537   epsilon: 1.0    steps: 245    lr: 0.0001     evaluation reward: 1.51\n",
            "episode: 493   score: 2.0   memory length: 89736   epsilon: 1.0    steps: 199    lr: 0.0001     evaluation reward: 1.53\n",
            "episode: 494   score: 0.0   memory length: 89860   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.53\n",
            "episode: 495   score: 1.0   memory length: 90029   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.52\n",
            "episode: 496   score: 2.0   memory length: 90229   epsilon: 1.0    steps: 200    lr: 0.0001     evaluation reward: 1.53\n",
            "episode: 497   score: 1.0   memory length: 90399   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.51\n",
            "episode: 498   score: 1.0   memory length: 90569   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.52\n",
            "episode: 499   score: 0.0   memory length: 90693   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.45\n",
            "episode: 500   score: 0.0   memory length: 90817   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.42\n",
            "episode: 501   score: 0.0   memory length: 90941   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.39\n",
            "episode: 502   score: 2.0   memory length: 91160   epsilon: 1.0    steps: 219    lr: 0.0001     evaluation reward: 1.4\n",
            "episode: 503   score: 2.0   memory length: 91359   epsilon: 1.0    steps: 199    lr: 0.0001     evaluation reward: 1.42\n",
            "episode: 504   score: 0.0   memory length: 91483   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.41\n",
            "episode: 505   score: 1.0   memory length: 91653   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.38\n",
            "episode: 506   score: 0.0   memory length: 91777   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.36\n",
            "episode: 507   score: 5.0   memory length: 92101   epsilon: 1.0    steps: 324    lr: 0.0001     evaluation reward: 1.38\n",
            "episode: 508   score: 1.0   memory length: 92253   epsilon: 1.0    steps: 152    lr: 0.0001     evaluation reward: 1.38\n",
            "episode: 509   score: 0.0   memory length: 92377   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.37\n",
            "episode: 510   score: 1.0   memory length: 92529   epsilon: 1.0    steps: 152    lr: 0.0001     evaluation reward: 1.36\n",
            "episode: 511   score: 1.0   memory length: 92681   epsilon: 1.0    steps: 152    lr: 0.0001     evaluation reward: 1.35\n",
            "episode: 512   score: 1.0   memory length: 92853   epsilon: 1.0    steps: 172    lr: 0.0001     evaluation reward: 1.35\n",
            "episode: 513   score: 3.0   memory length: 93121   epsilon: 1.0    steps: 268    lr: 0.0001     evaluation reward: 1.36\n",
            "episode: 514   score: 0.0   memory length: 93245   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.35\n",
            "episode: 515   score: 0.0   memory length: 93369   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.35\n",
            "episode: 516   score: 1.0   memory length: 93539   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.34\n",
            "episode: 517   score: 2.0   memory length: 93758   epsilon: 1.0    steps: 219    lr: 0.0001     evaluation reward: 1.36\n",
            "episode: 518   score: 0.0   memory length: 93882   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.35\n",
            "episode: 519   score: 1.0   memory length: 94033   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.36\n",
            "episode: 520   score: 1.0   memory length: 94185   epsilon: 1.0    steps: 152    lr: 0.0001     evaluation reward: 1.36\n",
            "episode: 521   score: 0.0   memory length: 94308   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.34\n",
            "episode: 522   score: 0.0   memory length: 94432   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.34\n",
            "episode: 523   score: 1.0   memory length: 94603   epsilon: 1.0    steps: 171    lr: 0.0001     evaluation reward: 1.31\n",
            "episode: 524   score: 1.0   memory length: 94755   epsilon: 1.0    steps: 152    lr: 0.0001     evaluation reward: 1.3\n",
            "episode: 525   score: 1.0   memory length: 94927   epsilon: 1.0    steps: 172    lr: 0.0001     evaluation reward: 1.28\n",
            "episode: 526   score: 5.0   memory length: 95270   epsilon: 1.0    steps: 343    lr: 0.0001     evaluation reward: 1.32\n",
            "episode: 527   score: 1.0   memory length: 95422   epsilon: 1.0    steps: 152    lr: 0.0001     evaluation reward: 1.33\n",
            "episode: 528   score: 4.0   memory length: 95722   epsilon: 1.0    steps: 300    lr: 0.0001     evaluation reward: 1.35\n",
            "episode: 529   score: 2.0   memory length: 95905   epsilon: 1.0    steps: 183    lr: 0.0001     evaluation reward: 1.3\n",
            "episode: 530   score: 2.0   memory length: 96122   epsilon: 1.0    steps: 217    lr: 0.0001     evaluation reward: 1.29\n",
            "episode: 531   score: 0.0   memory length: 96246   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.27\n",
            "episode: 532   score: 3.0   memory length: 96474   epsilon: 1.0    steps: 228    lr: 0.0001     evaluation reward: 1.27\n",
            "episode: 533   score: 2.0   memory length: 96673   epsilon: 1.0    steps: 199    lr: 0.0001     evaluation reward: 1.29\n",
            "episode: 534   score: 1.0   memory length: 96843   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.29\n",
            "episode: 535   score: 0.0   memory length: 96967   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.27\n",
            "episode: 536   score: 3.0   memory length: 97236   epsilon: 1.0    steps: 269    lr: 0.0001     evaluation reward: 1.29\n",
            "episode: 537   score: 3.0   memory length: 97466   epsilon: 1.0    steps: 230    lr: 0.0001     evaluation reward: 1.28\n",
            "episode: 538   score: 2.0   memory length: 97665   epsilon: 1.0    steps: 199    lr: 0.0001     evaluation reward: 1.28\n",
            "episode: 539   score: 2.0   memory length: 97883   epsilon: 1.0    steps: 218    lr: 0.0001     evaluation reward: 1.3\n",
            "episode: 540   score: 1.0   memory length: 98053   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.31\n",
            "episode: 541   score: 2.0   memory length: 98254   epsilon: 1.0    steps: 201    lr: 0.0001     evaluation reward: 1.32\n",
            "episode: 542   score: 0.0   memory length: 98378   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.29\n",
            "episode: 543   score: 2.0   memory length: 98598   epsilon: 1.0    steps: 220    lr: 0.0001     evaluation reward: 1.29\n",
            "episode: 544   score: 1.0   memory length: 98768   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.3\n",
            "episode: 545   score: 5.0   memory length: 99096   epsilon: 1.0    steps: 328    lr: 0.0001     evaluation reward: 1.33\n",
            "episode: 546   score: 2.0   memory length: 99316   epsilon: 1.0    steps: 220    lr: 0.0001     evaluation reward: 1.35\n",
            "episode: 547   score: 1.0   memory length: 99485   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.35\n",
            "episode: 548   score: 1.0   memory length: 99657   epsilon: 1.0    steps: 172    lr: 0.0001     evaluation reward: 1.34\n",
            "episode: 549   score: 0.0   memory length: 99781   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.33\n",
            "episode: 550   score: 0.0   memory length: 99904   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.33\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/gdrive/MyDrive/DRL_747_Clone/memory.py:30: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  sample = np.array(sample)\n",
            "/content/gdrive/MyDrive/DRL_747_Clone/agent.py:77: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  mini_batch = np.array(mini_batch).transpose()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "episode: 551   score: 4.0   memory length: 100201   epsilon: 0.9996000400000087    steps: 297    lr: 0.0001     evaluation reward: 1.37\n",
            "episode: 552   score: 3.0   memory length: 100449   epsilon: 0.9991090000000193    steps: 248    lr: 0.0001     evaluation reward: 1.4\n",
            "episode: 553   score: 2.0   memory length: 100667   epsilon: 0.9986773600000287    steps: 218    lr: 0.0001     evaluation reward: 1.42\n",
            "episode: 554   score: 0.0   memory length: 100790   epsilon: 0.998433820000034    steps: 123    lr: 0.0001     evaluation reward: 1.42\n",
            "episode: 555   score: 3.0   memory length: 101021   epsilon: 0.9979764400000439    steps: 231    lr: 0.0001     evaluation reward: 1.43\n",
            "episode: 556   score: 4.0   memory length: 101316   epsilon: 0.9973923400000566    steps: 295    lr: 0.0001     evaluation reward: 1.47\n",
            "episode: 557   score: 2.0   memory length: 101515   epsilon: 0.9969983200000652    steps: 199    lr: 0.0001     evaluation reward: 1.46\n",
            "episode: 558   score: 4.0   memory length: 101791   epsilon: 0.996451840000077    steps: 276    lr: 0.0001     evaluation reward: 1.48\n",
            "episode: 559   score: 0.0   memory length: 101915   epsilon: 0.9962063200000824    steps: 124    lr: 0.0001     evaluation reward: 1.47\n",
            "episode: 560   score: 5.0   memory length: 102244   epsilon: 0.9955549000000965    steps: 329    lr: 0.0001     evaluation reward: 1.47\n",
            "episode: 561   score: 0.0   memory length: 102368   epsilon: 0.9953093800001018    steps: 124    lr: 0.0001     evaluation reward: 1.44\n",
            "episode: 562   score: 1.0   memory length: 102538   epsilon: 0.9949727800001091    steps: 170    lr: 0.0001     evaluation reward: 1.43\n",
            "episode: 563   score: 1.0   memory length: 102690   epsilon: 0.9946718200001157    steps: 152    lr: 0.0001     evaluation reward: 1.44\n",
            "episode: 564   score: 1.0   memory length: 102841   epsilon: 0.9943728400001222    steps: 151    lr: 0.0001     evaluation reward: 1.45\n",
            "episode: 565   score: 3.0   memory length: 103067   epsilon: 0.9939253600001319    steps: 226    lr: 0.0001     evaluation reward: 1.46\n",
            "episode: 566   score: 1.0   memory length: 103237   epsilon: 0.9935887600001392    steps: 170    lr: 0.0001     evaluation reward: 1.45\n",
            "episode: 567   score: 2.0   memory length: 103456   epsilon: 0.9931551400001486    steps: 219    lr: 0.0001     evaluation reward: 1.45\n",
            "episode: 568   score: 0.0   memory length: 103580   epsilon: 0.9929096200001539    steps: 124    lr: 0.0001     evaluation reward: 1.45\n",
            "episode: 569   score: 1.0   memory length: 103753   epsilon: 0.9925670800001614    steps: 173    lr: 0.0001     evaluation reward: 1.44\n",
            "episode: 570   score: 1.0   memory length: 103923   epsilon: 0.9922304800001687    steps: 170    lr: 0.0001     evaluation reward: 1.45\n",
            "episode: 571   score: 3.0   memory length: 104150   epsilon: 0.9917810200001784    steps: 227    lr: 0.0001     evaluation reward: 1.46\n",
            "episode: 572   score: 0.0   memory length: 104274   epsilon: 0.9915355000001838    steps: 124    lr: 0.0001     evaluation reward: 1.45\n",
            "episode: 573   score: 0.0   memory length: 104397   epsilon: 0.991291960000189    steps: 123    lr: 0.0001     evaluation reward: 1.4\n",
            "episode: 574   score: 0.0   memory length: 104520   epsilon: 0.9910484200001943    steps: 123    lr: 0.0001     evaluation reward: 1.38\n",
            "episode: 575   score: 1.0   memory length: 104691   epsilon: 0.9907098400002017    steps: 171    lr: 0.0001     evaluation reward: 1.38\n",
            "episode: 576   score: 2.0   memory length: 104890   epsilon: 0.9903158200002102    steps: 199    lr: 0.0001     evaluation reward: 1.4\n",
            "episode: 577   score: 2.0   memory length: 105108   epsilon: 0.9898841800002196    steps: 218    lr: 0.0001     evaluation reward: 1.42\n",
            "episode: 578   score: 3.0   memory length: 105357   epsilon: 0.9893911600002303    steps: 249    lr: 0.0001     evaluation reward: 1.44\n",
            "episode: 579   score: 2.0   memory length: 105555   epsilon: 0.9889991200002388    steps: 198    lr: 0.0001     evaluation reward: 1.43\n",
            "episode: 580   score: 2.0   memory length: 105774   epsilon: 0.9885655000002482    steps: 219    lr: 0.0001     evaluation reward: 1.44\n",
            "episode: 581   score: 2.0   memory length: 105972   epsilon: 0.9881734600002567    steps: 198    lr: 0.0001     evaluation reward: 1.45\n",
            "episode: 582   score: 5.0   memory length: 106322   epsilon: 0.9874804600002718    steps: 350    lr: 0.0001     evaluation reward: 1.5\n",
            "episode: 583   score: 3.0   memory length: 106549   epsilon: 0.9870310000002815    steps: 227    lr: 0.0001     evaluation reward: 1.53\n",
            "episode: 584   score: 4.0   memory length: 106849   epsilon: 0.9864370000002944    steps: 300    lr: 0.0001     evaluation reward: 1.56\n",
            "episode: 585   score: 3.0   memory length: 107097   epsilon: 0.9859459600003051    steps: 248    lr: 0.0001     evaluation reward: 1.58\n",
            "episode: 586   score: 3.0   memory length: 107324   epsilon: 0.9854965000003149    steps: 227    lr: 0.0001     evaluation reward: 1.59\n",
            "episode: 587   score: 2.0   memory length: 107522   epsilon: 0.9851044600003234    steps: 198    lr: 0.0001     evaluation reward: 1.6\n",
            "episode: 588   score: 3.0   memory length: 107772   epsilon: 0.9846094600003341    steps: 250    lr: 0.0001     evaluation reward: 1.63\n",
            "episode: 589   score: 2.0   memory length: 107973   epsilon: 0.9842114800003428    steps: 201    lr: 0.0001     evaluation reward: 1.65\n",
            "episode: 590   score: 0.0   memory length: 108097   epsilon: 0.9839659600003481    steps: 124    lr: 0.0001     evaluation reward: 1.62\n",
            "episode: 591   score: 0.0   memory length: 108221   epsilon: 0.9837204400003534    steps: 124    lr: 0.0001     evaluation reward: 1.61\n",
            "episode: 592   score: 0.0   memory length: 108344   epsilon: 0.9834769000003587    steps: 123    lr: 0.0001     evaluation reward: 1.57\n",
            "episode: 593   score: 2.0   memory length: 108543   epsilon: 0.9830828800003673    steps: 199    lr: 0.0001     evaluation reward: 1.57\n",
            "episode: 594   score: 1.0   memory length: 108712   epsilon: 0.9827482600003745    steps: 169    lr: 0.0001     evaluation reward: 1.58\n",
            "episode: 595   score: 4.0   memory length: 108951   epsilon: 0.9822750400003848    steps: 239    lr: 0.0001     evaluation reward: 1.61\n",
            "episode: 596   score: 0.0   memory length: 109075   epsilon: 0.9820295200003901    steps: 124    lr: 0.0001     evaluation reward: 1.59\n",
            "episode: 597   score: 1.0   memory length: 109226   epsilon: 0.9817305400003966    steps: 151    lr: 0.0001     evaluation reward: 1.59\n",
            "episode: 598   score: 2.0   memory length: 109448   epsilon: 0.9812909800004062    steps: 222    lr: 0.0001     evaluation reward: 1.6\n",
            "episode: 599   score: 2.0   memory length: 109647   epsilon: 0.9808969600004147    steps: 199    lr: 0.0001     evaluation reward: 1.62\n",
            "episode: 600   score: 1.0   memory length: 109819   epsilon: 0.9805564000004221    steps: 172    lr: 0.0001     evaluation reward: 1.63\n",
            "episode: 601   score: 2.0   memory length: 110018   epsilon: 0.9801623800004307    steps: 199    lr: 0.0001     evaluation reward: 1.65\n",
            "episode: 602   score: 2.0   memory length: 110217   epsilon: 0.9797683600004392    steps: 199    lr: 0.0001     evaluation reward: 1.65\n",
            "episode: 603   score: 3.0   memory length: 110443   epsilon: 0.9793208800004489    steps: 226    lr: 0.0001     evaluation reward: 1.66\n",
            "episode: 604   score: 2.0   memory length: 110642   epsilon: 0.9789268600004575    steps: 199    lr: 0.0001     evaluation reward: 1.68\n",
            "episode: 605   score: 2.0   memory length: 110840   epsilon: 0.978534820000466    steps: 198    lr: 0.0001     evaluation reward: 1.69\n",
            "episode: 606   score: 2.0   memory length: 111059   epsilon: 0.9781012000004754    steps: 219    lr: 0.0001     evaluation reward: 1.71\n",
            "episode: 607   score: 2.0   memory length: 111261   epsilon: 0.9777012400004841    steps: 202    lr: 0.0001     evaluation reward: 1.68\n",
            "episode: 608   score: 2.0   memory length: 111477   epsilon: 0.9772735600004934    steps: 216    lr: 0.0001     evaluation reward: 1.69\n",
            "episode: 609   score: 0.0   memory length: 111601   epsilon: 0.9770280400004987    steps: 124    lr: 0.0001     evaluation reward: 1.69\n",
            "episode: 610   score: 0.0   memory length: 111724   epsilon: 0.976784500000504    steps: 123    lr: 0.0001     evaluation reward: 1.68\n",
            "episode: 611   score: 1.0   memory length: 111876   epsilon: 0.9764835400005105    steps: 152    lr: 0.0001     evaluation reward: 1.68\n",
            "episode: 612   score: 3.0   memory length: 112124   epsilon: 0.9759925000005212    steps: 248    lr: 0.0001     evaluation reward: 1.7\n",
            "episode: 613   score: 0.0   memory length: 112248   epsilon: 0.9757469800005265    steps: 124    lr: 0.0001     evaluation reward: 1.67\n",
            "episode: 614   score: 0.0   memory length: 112371   epsilon: 0.9755034400005318    steps: 123    lr: 0.0001     evaluation reward: 1.67\n",
            "episode: 615   score: 0.0   memory length: 112495   epsilon: 0.9752579200005371    steps: 124    lr: 0.0001     evaluation reward: 1.67\n",
            "episode: 616   score: 0.0   memory length: 112618   epsilon: 0.9750143800005424    steps: 123    lr: 0.0001     evaluation reward: 1.66\n",
            "episode: 617   score: 1.0   memory length: 112770   epsilon: 0.974713420000549    steps: 152    lr: 0.0001     evaluation reward: 1.65\n",
            "episode: 618   score: 3.0   memory length: 113000   epsilon: 0.9742580200005588    steps: 230    lr: 0.0001     evaluation reward: 1.68\n",
            "episode: 619   score: 1.0   memory length: 113170   epsilon: 0.9739214200005661    steps: 170    lr: 0.0001     evaluation reward: 1.68\n",
            "episode: 620   score: 2.0   memory length: 113371   epsilon: 0.9735234400005748    steps: 201    lr: 0.0001     evaluation reward: 1.69\n",
            "episode: 621   score: 0.0   memory length: 113494   epsilon: 0.9732799000005801    steps: 123    lr: 0.0001     evaluation reward: 1.69\n",
            "episode: 622   score: 2.0   memory length: 113693   epsilon: 0.9728858800005886    steps: 199    lr: 0.0001     evaluation reward: 1.71\n",
            "episode: 623   score: 2.0   memory length: 113913   epsilon: 0.9724502800005981    steps: 220    lr: 0.0001     evaluation reward: 1.72\n",
            "episode: 624   score: 3.0   memory length: 114161   epsilon: 0.9719592400006087    steps: 248    lr: 0.0001     evaluation reward: 1.74\n",
            "episode: 625   score: 0.0   memory length: 114284   epsilon: 0.971715700000614    steps: 123    lr: 0.0001     evaluation reward: 1.73\n",
            "episode: 626   score: 2.0   memory length: 114483   epsilon: 0.9713216800006226    steps: 199    lr: 0.0001     evaluation reward: 1.7\n",
            "episode: 627   score: 1.0   memory length: 114635   epsilon: 0.9710207200006291    steps: 152    lr: 0.0001     evaluation reward: 1.7\n",
            "episode: 628   score: 2.0   memory length: 114852   epsilon: 0.9705910600006384    steps: 217    lr: 0.0001     evaluation reward: 1.68\n",
            "episode: 629   score: 0.0   memory length: 114976   epsilon: 0.9703455400006438    steps: 124    lr: 0.0001     evaluation reward: 1.66\n",
            "episode: 630   score: 1.0   memory length: 115148   epsilon: 0.9700049800006512    steps: 172    lr: 0.0001     evaluation reward: 1.65\n",
            "episode: 631   score: 0.0   memory length: 115272   epsilon: 0.9697594600006565    steps: 124    lr: 0.0001     evaluation reward: 1.65\n",
            "episode: 632   score: 1.0   memory length: 115423   epsilon: 0.969460480000663    steps: 151    lr: 0.0001     evaluation reward: 1.63\n",
            "episode: 633   score: 2.0   memory length: 115640   epsilon: 0.9690308200006723    steps: 217    lr: 0.0001     evaluation reward: 1.63\n",
            "episode: 634   score: 2.0   memory length: 115857   epsilon: 0.9686011600006816    steps: 217    lr: 0.0001     evaluation reward: 1.64\n",
            "episode: 635   score: 0.0   memory length: 115980   epsilon: 0.9683576200006869    steps: 123    lr: 0.0001     evaluation reward: 1.64\n",
            "episode: 636   score: 1.0   memory length: 116132   epsilon: 0.9680566600006935    steps: 152    lr: 0.0001     evaluation reward: 1.62\n",
            "episode: 637   score: 2.0   memory length: 116331   epsilon: 0.967662640000702    steps: 199    lr: 0.0001     evaluation reward: 1.61\n",
            "episode: 638   score: 1.0   memory length: 116482   epsilon: 0.9673636600007085    steps: 151    lr: 0.0001     evaluation reward: 1.6\n",
            "episode: 639   score: 0.0   memory length: 116605   epsilon: 0.9671201200007138    steps: 123    lr: 0.0001     evaluation reward: 1.58\n",
            "episode: 640   score: 3.0   memory length: 116833   epsilon: 0.9666686800007236    steps: 228    lr: 0.0001     evaluation reward: 1.6\n",
            "episode: 641   score: 0.0   memory length: 116956   epsilon: 0.9664251400007289    steps: 123    lr: 0.0001     evaluation reward: 1.58\n",
            "episode: 642   score: 0.0   memory length: 117080   epsilon: 0.9661796200007342    steps: 124    lr: 0.0001     evaluation reward: 1.58\n",
            "episode: 643   score: 0.0   memory length: 117204   epsilon: 0.9659341000007395    steps: 124    lr: 0.0001     evaluation reward: 1.56\n",
            "episode: 644   score: 2.0   memory length: 117403   epsilon: 0.9655400800007481    steps: 199    lr: 0.0001     evaluation reward: 1.57\n",
            "episode: 645   score: 1.0   memory length: 117573   epsilon: 0.9652034800007554    steps: 170    lr: 0.0001     evaluation reward: 1.53\n",
            "episode: 646   score: 0.0   memory length: 117697   epsilon: 0.9649579600007607    steps: 124    lr: 0.0001     evaluation reward: 1.51\n",
            "episode: 647   score: 2.0   memory length: 117878   epsilon: 0.9645995800007685    steps: 181    lr: 0.0001     evaluation reward: 1.52\n",
            "episode: 648   score: 1.0   memory length: 118049   epsilon: 0.9642610000007759    steps: 171    lr: 0.0001     evaluation reward: 1.52\n",
            "episode: 649   score: 0.0   memory length: 118172   epsilon: 0.9640174600007811    steps: 123    lr: 0.0001     evaluation reward: 1.52\n",
            "episode: 650   score: 2.0   memory length: 118392   epsilon: 0.9635818600007906    steps: 220    lr: 0.0001     evaluation reward: 1.54\n",
            "episode: 651   score: 2.0   memory length: 118612   epsilon: 0.9631462600008001    steps: 220    lr: 0.0001     evaluation reward: 1.52\n",
            "episode: 652   score: 3.0   memory length: 118824   epsilon: 0.9627265000008092    steps: 212    lr: 0.0001     evaluation reward: 1.52\n",
            "episode: 653   score: 2.0   memory length: 119023   epsilon: 0.9623324800008177    steps: 199    lr: 0.0001     evaluation reward: 1.52\n",
            "episode: 654   score: 1.0   memory length: 119194   epsilon: 0.9619939000008251    steps: 171    lr: 0.0001     evaluation reward: 1.53\n",
            "episode: 655   score: 0.0   memory length: 119317   epsilon: 0.9617503600008304    steps: 123    lr: 0.0001     evaluation reward: 1.5\n",
            "episode: 656   score: 6.0   memory length: 119681   epsilon: 0.961029640000846    steps: 364    lr: 0.0001     evaluation reward: 1.52\n",
            "episode: 657   score: 0.0   memory length: 119804   epsilon: 0.9607861000008513    steps: 123    lr: 0.0001     evaluation reward: 1.5\n",
            "episode: 658   score: 2.0   memory length: 120024   epsilon: 0.9603505000008608    steps: 220    lr: 0.0001     evaluation reward: 1.48\n",
            "episode: 659   score: 0.0   memory length: 120147   epsilon: 0.960106960000866    steps: 123    lr: 0.0001     evaluation reward: 1.48\n",
            "episode: 660   score: 0.0   memory length: 120270   epsilon: 0.9598634200008713    steps: 123    lr: 0.0001     evaluation reward: 1.43\n",
            "episode: 661   score: 2.0   memory length: 120469   epsilon: 0.9594694000008799    steps: 199    lr: 0.0001     evaluation reward: 1.45\n",
            "episode: 662   score: 0.0   memory length: 120593   epsilon: 0.9592238800008852    steps: 124    lr: 0.0001     evaluation reward: 1.44\n",
            "episode: 663   score: 2.0   memory length: 120812   epsilon: 0.9587902600008946    steps: 219    lr: 0.0001     evaluation reward: 1.45\n",
            "episode: 664   score: 0.0   memory length: 120936   epsilon: 0.9585447400009    steps: 124    lr: 0.0001     evaluation reward: 1.44\n",
            "episode: 665   score: 0.0   memory length: 121059   epsilon: 0.9583012000009052    steps: 123    lr: 0.0001     evaluation reward: 1.41\n",
            "episode: 666   score: 3.0   memory length: 121307   epsilon: 0.9578101600009159    steps: 248    lr: 0.0001     evaluation reward: 1.43\n",
            "episode: 667   score: 1.0   memory length: 121459   epsilon: 0.9575092000009224    steps: 152    lr: 0.0001     evaluation reward: 1.42\n",
            "episode: 668   score: 1.0   memory length: 121629   epsilon: 0.9571726000009297    steps: 170    lr: 0.0001     evaluation reward: 1.43\n",
            "episode: 669   score: 0.0   memory length: 121752   epsilon: 0.956929060000935    steps: 123    lr: 0.0001     evaluation reward: 1.42\n",
            "episode: 670   score: 2.0   memory length: 121950   epsilon: 0.9565370200009435    steps: 198    lr: 0.0001     evaluation reward: 1.43\n",
            "episode: 671   score: 3.0   memory length: 122177   epsilon: 0.9560875600009533    steps: 227    lr: 0.0001     evaluation reward: 1.43\n",
            "episode: 672   score: 2.0   memory length: 122396   epsilon: 0.9556539400009627    steps: 219    lr: 0.0001     evaluation reward: 1.45\n",
            "episode: 673   score: 2.0   memory length: 122595   epsilon: 0.9552599200009713    steps: 199    lr: 0.0001     evaluation reward: 1.47\n",
            "episode: 674   score: 1.0   memory length: 122746   epsilon: 0.9549609400009778    steps: 151    lr: 0.0001     evaluation reward: 1.48\n",
            "episode: 675   score: 0.0   memory length: 122869   epsilon: 0.954717400000983    steps: 123    lr: 0.0001     evaluation reward: 1.47\n",
            "episode: 676   score: 1.0   memory length: 123042   epsilon: 0.9543748600009905    steps: 173    lr: 0.0001     evaluation reward: 1.46\n",
            "episode: 677   score: 3.0   memory length: 123271   epsilon: 0.9539214400010003    steps: 229    lr: 0.0001     evaluation reward: 1.47\n",
            "episode: 678   score: 0.0   memory length: 123395   epsilon: 0.9536759200010057    steps: 124    lr: 0.0001     evaluation reward: 1.44\n",
            "episode: 679   score: 2.0   memory length: 123613   epsilon: 0.953244280001015    steps: 218    lr: 0.0001     evaluation reward: 1.44\n",
            "episode: 680   score: 1.0   memory length: 123783   epsilon: 0.9529076800010223    steps: 170    lr: 0.0001     evaluation reward: 1.43\n",
            "episode: 681   score: 4.0   memory length: 124056   epsilon: 0.9523671400010341    steps: 273    lr: 0.0001     evaluation reward: 1.45\n",
            "episode: 682   score: 4.0   memory length: 124352   epsilon: 0.9517810600010468    steps: 296    lr: 0.0001     evaluation reward: 1.44\n",
            "episode: 683   score: 1.0   memory length: 124521   epsilon: 0.951446440001054    steps: 169    lr: 0.0001     evaluation reward: 1.42\n",
            "episode: 684   score: 1.0   memory length: 124694   epsilon: 0.9511039000010615    steps: 173    lr: 0.0001     evaluation reward: 1.39\n",
            "episode: 685   score: 2.0   memory length: 124895   epsilon: 0.9507059200010701    steps: 201    lr: 0.0001     evaluation reward: 1.38\n",
            "episode: 686   score: 1.0   memory length: 125064   epsilon: 0.9503713000010774    steps: 169    lr: 0.0001     evaluation reward: 1.36\n",
            "episode: 687   score: 1.0   memory length: 125237   epsilon: 0.9500287600010848    steps: 173    lr: 0.0001     evaluation reward: 1.35\n",
            "episode: 688   score: 0.0   memory length: 125361   epsilon: 0.9497832400010902    steps: 124    lr: 0.0001     evaluation reward: 1.32\n",
            "episode: 689   score: 0.0   memory length: 125485   epsilon: 0.9495377200010955    steps: 124    lr: 0.0001     evaluation reward: 1.3\n",
            "episode: 690   score: 0.0   memory length: 125609   epsilon: 0.9492922000011008    steps: 124    lr: 0.0001     evaluation reward: 1.3\n",
            "episode: 691   score: 5.0   memory length: 125954   epsilon: 0.9486091000011156    steps: 345    lr: 0.0001     evaluation reward: 1.35\n",
            "episode: 692   score: 1.0   memory length: 126106   epsilon: 0.9483081400011222    steps: 152    lr: 0.0001     evaluation reward: 1.36\n",
            "episode: 693   score: 1.0   memory length: 126279   epsilon: 0.9479656000011296    steps: 173    lr: 0.0001     evaluation reward: 1.35\n",
            "episode: 694   score: 1.0   memory length: 126430   epsilon: 0.9476666200011361    steps: 151    lr: 0.0001     evaluation reward: 1.35\n",
            "episode: 695   score: 8.0   memory length: 126904   epsilon: 0.9467281000011565    steps: 474    lr: 0.0001     evaluation reward: 1.39\n",
            "episode: 696   score: 1.0   memory length: 127056   epsilon: 0.946427140001163    steps: 152    lr: 0.0001     evaluation reward: 1.4\n",
            "episode: 697   score: 0.0   memory length: 127179   epsilon: 0.9461836000011683    steps: 123    lr: 0.0001     evaluation reward: 1.39\n",
            "episode: 698   score: 0.0   memory length: 127303   epsilon: 0.9459380800011736    steps: 124    lr: 0.0001     evaluation reward: 1.37\n",
            "episode: 699   score: 3.0   memory length: 127551   epsilon: 0.9454470400011843    steps: 248    lr: 0.0001     evaluation reward: 1.38\n",
            "episode: 700   score: 2.0   memory length: 127771   epsilon: 0.9450114400011937    steps: 220    lr: 0.0001     evaluation reward: 1.39\n",
            "episode: 701   score: 1.0   memory length: 127923   epsilon: 0.9447104800012003    steps: 152    lr: 0.0001     evaluation reward: 1.38\n",
            "episode: 702   score: 0.0   memory length: 128047   epsilon: 0.9444649600012056    steps: 124    lr: 0.0001     evaluation reward: 1.36\n",
            "episode: 703   score: 2.0   memory length: 128246   epsilon: 0.9440709400012142    steps: 199    lr: 0.0001     evaluation reward: 1.35\n",
            "episode: 704   score: 2.0   memory length: 128464   epsilon: 0.9436393000012235    steps: 218    lr: 0.0001     evaluation reward: 1.35\n",
            "episode: 705   score: 0.0   memory length: 128588   epsilon: 0.9433937800012289    steps: 124    lr: 0.0001     evaluation reward: 1.33\n",
            "episode: 706   score: 2.0   memory length: 128787   epsilon: 0.9429997600012374    steps: 199    lr: 0.0001     evaluation reward: 1.33\n",
            "episode: 707   score: 0.0   memory length: 128911   epsilon: 0.9427542400012427    steps: 124    lr: 0.0001     evaluation reward: 1.31\n",
            "episode: 708   score: 3.0   memory length: 129161   epsilon: 0.9422592400012535    steps: 250    lr: 0.0001     evaluation reward: 1.32\n",
            "episode: 709   score: 1.0   memory length: 129331   epsilon: 0.9419226400012608    steps: 170    lr: 0.0001     evaluation reward: 1.33\n",
            "episode: 710   score: 1.0   memory length: 129502   epsilon: 0.9415840600012682    steps: 171    lr: 0.0001     evaluation reward: 1.34\n",
            "episode: 711   score: 5.0   memory length: 129841   epsilon: 0.9409128400012827    steps: 339    lr: 0.0001     evaluation reward: 1.38\n",
            "episode: 712   score: 3.0   memory length: 130089   epsilon: 0.9404218000012934    steps: 248    lr: 0.0001     evaluation reward: 1.38\n",
            "episode: 713   score: 2.0   memory length: 130288   epsilon: 0.9400277800013019    steps: 199    lr: 0.0001     evaluation reward: 1.4\n",
            "episode: 714   score: 2.0   memory length: 130505   epsilon: 0.9395981200013113    steps: 217    lr: 0.0001     evaluation reward: 1.42\n",
            "episode: 715   score: 1.0   memory length: 130675   epsilon: 0.9392615200013186    steps: 170    lr: 0.0001     evaluation reward: 1.43\n",
            "episode: 716   score: 0.0   memory length: 130799   epsilon: 0.9390160000013239    steps: 124    lr: 0.0001     evaluation reward: 1.43\n",
            "episode: 717   score: 0.0   memory length: 130923   epsilon: 0.9387704800013292    steps: 124    lr: 0.0001     evaluation reward: 1.42\n",
            "episode: 718   score: 2.0   memory length: 131121   epsilon: 0.9383784400013377    steps: 198    lr: 0.0001     evaluation reward: 1.41\n",
            "episode: 719   score: 1.0   memory length: 131291   epsilon: 0.938041840001345    steps: 170    lr: 0.0001     evaluation reward: 1.41\n",
            "episode: 720   score: 2.0   memory length: 131510   epsilon: 0.9376082200013545    steps: 219    lr: 0.0001     evaluation reward: 1.41\n",
            "episode: 721   score: 0.0   memory length: 131634   epsilon: 0.9373627000013598    steps: 124    lr: 0.0001     evaluation reward: 1.41\n",
            "episode: 722   score: 4.0   memory length: 131948   epsilon: 0.9367409800013733    steps: 314    lr: 0.0001     evaluation reward: 1.43\n",
            "episode: 723   score: 2.0   memory length: 132147   epsilon: 0.9363469600013818    steps: 199    lr: 0.0001     evaluation reward: 1.43\n",
            "episode: 724   score: 0.0   memory length: 132271   epsilon: 0.9361014400013872    steps: 124    lr: 0.0001     evaluation reward: 1.4\n",
            "episode: 725   score: 2.0   memory length: 132469   epsilon: 0.9357094000013957    steps: 198    lr: 0.0001     evaluation reward: 1.42\n",
            "episode: 726   score: 3.0   memory length: 132714   epsilon: 0.9352243000014062    steps: 245    lr: 0.0001     evaluation reward: 1.43\n",
            "episode: 727   score: 0.0   memory length: 132838   epsilon: 0.9349787800014115    steps: 124    lr: 0.0001     evaluation reward: 1.42\n",
            "episode: 728   score: 2.0   memory length: 133037   epsilon: 0.9345847600014201    steps: 199    lr: 0.0001     evaluation reward: 1.42\n",
            "episode: 729   score: 0.0   memory length: 133161   epsilon: 0.9343392400014254    steps: 124    lr: 0.0001     evaluation reward: 1.42\n",
            "episode: 730   score: 3.0   memory length: 133428   epsilon: 0.9338105800014369    steps: 267    lr: 0.0001     evaluation reward: 1.44\n",
            "episode: 731   score: 3.0   memory length: 133697   epsilon: 0.9332779600014485    steps: 269    lr: 0.0001     evaluation reward: 1.47\n",
            "episode: 732   score: 2.0   memory length: 133899   epsilon: 0.9328780000014572    steps: 202    lr: 0.0001     evaluation reward: 1.48\n",
            "episode: 733   score: 0.0   memory length: 134022   epsilon: 0.9326344600014624    steps: 123    lr: 0.0001     evaluation reward: 1.46\n",
            "episode: 734   score: 3.0   memory length: 134269   epsilon: 0.9321454000014731    steps: 247    lr: 0.0001     evaluation reward: 1.47\n",
            "episode: 735   score: 0.0   memory length: 134392   epsilon: 0.9319018600014783    steps: 123    lr: 0.0001     evaluation reward: 1.47\n",
            "episode: 736   score: 0.0   memory length: 134516   epsilon: 0.9316563400014837    steps: 124    lr: 0.0001     evaluation reward: 1.46\n",
            "episode: 737   score: 1.0   memory length: 134667   epsilon: 0.9313573600014902    steps: 151    lr: 0.0001     evaluation reward: 1.45\n",
            "episode: 738   score: 0.0   memory length: 134790   epsilon: 0.9311138200014955    steps: 123    lr: 0.0001     evaluation reward: 1.44\n",
            "episode: 739   score: 0.0   memory length: 134914   epsilon: 0.9308683000015008    steps: 124    lr: 0.0001     evaluation reward: 1.44\n",
            "episode: 740   score: 2.0   memory length: 135133   epsilon: 0.9304346800015102    steps: 219    lr: 0.0001     evaluation reward: 1.43\n",
            "episode: 741   score: 2.0   memory length: 135332   epsilon: 0.9300406600015187    steps: 199    lr: 0.0001     evaluation reward: 1.45\n",
            "episode: 742   score: 2.0   memory length: 135551   epsilon: 0.9296070400015282    steps: 219    lr: 0.0001     evaluation reward: 1.47\n",
            "episode: 743   score: 0.0   memory length: 135675   epsilon: 0.9293615200015335    steps: 124    lr: 0.0001     evaluation reward: 1.47\n",
            "episode: 744   score: 0.0   memory length: 135799   epsilon: 0.9291160000015388    steps: 124    lr: 0.0001     evaluation reward: 1.45\n",
            "episode: 745   score: 3.0   memory length: 136067   epsilon: 0.9285853600015503    steps: 268    lr: 0.0001     evaluation reward: 1.47\n",
            "episode: 746   score: 3.0   memory length: 136320   epsilon: 0.9280844200015612    steps: 253    lr: 0.0001     evaluation reward: 1.5\n",
            "episode: 747   score: 1.0   memory length: 136490   epsilon: 0.9277478200015685    steps: 170    lr: 0.0001     evaluation reward: 1.49\n",
            "episode: 748   score: 1.0   memory length: 136660   epsilon: 0.9274112200015758    steps: 170    lr: 0.0001     evaluation reward: 1.49\n",
            "episode: 749   score: 3.0   memory length: 136913   epsilon: 0.9269102800015867    steps: 253    lr: 0.0001     evaluation reward: 1.52\n",
            "episode: 750   score: 0.0   memory length: 137036   epsilon: 0.926666740001592    steps: 123    lr: 0.0001     evaluation reward: 1.5\n",
            "episode: 751   score: 0.0   memory length: 137160   epsilon: 0.9264212200015973    steps: 124    lr: 0.0001     evaluation reward: 1.48\n",
            "episode: 752   score: 1.0   memory length: 137332   epsilon: 0.9260806600016047    steps: 172    lr: 0.0001     evaluation reward: 1.46\n",
            "episode: 753   score: 0.0   memory length: 137455   epsilon: 0.92583712000161    steps: 123    lr: 0.0001     evaluation reward: 1.44\n",
            "episode: 754   score: 1.0   memory length: 137626   epsilon: 0.9254985400016174    steps: 171    lr: 0.0001     evaluation reward: 1.44\n",
            "episode: 755   score: 2.0   memory length: 137843   epsilon: 0.9250688800016267    steps: 217    lr: 0.0001     evaluation reward: 1.46\n",
            "episode: 756   score: 5.0   memory length: 138169   epsilon: 0.9244234000016407    steps: 326    lr: 0.0001     evaluation reward: 1.45\n",
            "episode: 757   score: 4.0   memory length: 138445   epsilon: 0.9238769200016526    steps: 276    lr: 0.0001     evaluation reward: 1.49\n",
            "episode: 758   score: 2.0   memory length: 138648   epsilon: 0.9234749800016613    steps: 203    lr: 0.0001     evaluation reward: 1.49\n",
            "episode: 759   score: 2.0   memory length: 138851   epsilon: 0.92307304000167    steps: 203    lr: 0.0001     evaluation reward: 1.51\n",
            "episode: 760   score: 0.0   memory length: 138975   epsilon: 0.9228275200016753    steps: 124    lr: 0.0001     evaluation reward: 1.51\n",
            "episode: 761   score: 1.0   memory length: 139147   epsilon: 0.9224869600016827    steps: 172    lr: 0.0001     evaluation reward: 1.5\n",
            "episode: 762   score: 0.0   memory length: 139270   epsilon: 0.922243420001688    steps: 123    lr: 0.0001     evaluation reward: 1.5\n",
            "episode: 763   score: 3.0   memory length: 139539   epsilon: 0.9217108000016996    steps: 269    lr: 0.0001     evaluation reward: 1.51\n",
            "episode: 764   score: 2.0   memory length: 139758   epsilon: 0.921277180001709    steps: 219    lr: 0.0001     evaluation reward: 1.53\n",
            "episode: 765   score: 0.0   memory length: 139881   epsilon: 0.9210336400017143    steps: 123    lr: 0.0001     evaluation reward: 1.53\n",
            "episode: 766   score: 3.0   memory length: 140145   epsilon: 0.9205109200017256    steps: 264    lr: 0.0001     evaluation reward: 1.53\n",
            "episode: 767   score: 1.0   memory length: 140296   epsilon: 0.9202119400017321    steps: 151    lr: 0.0001     evaluation reward: 1.53\n",
            "episode: 768   score: 2.0   memory length: 140477   epsilon: 0.9198535600017399    steps: 181    lr: 0.0001     evaluation reward: 1.54\n",
            "episode: 769   score: 1.0   memory length: 140647   epsilon: 0.9195169600017472    steps: 170    lr: 0.0001     evaluation reward: 1.55\n",
            "episode: 770   score: 2.0   memory length: 140845   epsilon: 0.9191249200017557    steps: 198    lr: 0.0001     evaluation reward: 1.55\n",
            "episode: 771   score: 0.0   memory length: 140969   epsilon: 0.918879400001761    steps: 124    lr: 0.0001     evaluation reward: 1.52\n",
            "episode: 772   score: 1.0   memory length: 141121   epsilon: 0.9185784400017676    steps: 152    lr: 0.0001     evaluation reward: 1.51\n",
            "episode: 773   score: 2.0   memory length: 141320   epsilon: 0.9181844200017761    steps: 199    lr: 0.0001     evaluation reward: 1.51\n",
            "episode: 774   score: 2.0   memory length: 141537   epsilon: 0.9177547600017855    steps: 217    lr: 0.0001     evaluation reward: 1.52\n",
            "episode: 775   score: 2.0   memory length: 141736   epsilon: 0.917360740001794    steps: 199    lr: 0.0001     evaluation reward: 1.54\n",
            "episode: 776   score: 2.0   memory length: 141934   epsilon: 0.9169687000018025    steps: 198    lr: 0.0001     evaluation reward: 1.55\n",
            "episode: 777   score: 3.0   memory length: 142182   epsilon: 0.9164776600018132    steps: 248    lr: 0.0001     evaluation reward: 1.55\n",
            "episode: 778   score: 0.0   memory length: 142305   epsilon: 0.9162341200018185    steps: 123    lr: 0.0001     evaluation reward: 1.55\n",
            "episode: 779   score: 0.0   memory length: 142429   epsilon: 0.9159886000018238    steps: 124    lr: 0.0001     evaluation reward: 1.53\n",
            "episode: 780   score: 5.0   memory length: 142735   epsilon: 0.915382720001837    steps: 306    lr: 0.0001     evaluation reward: 1.57\n",
            "episode: 781   score: 0.0   memory length: 142859   epsilon: 0.9151372000018423    steps: 124    lr: 0.0001     evaluation reward: 1.53\n",
            "episode: 782   score: 1.0   memory length: 143032   epsilon: 0.9147946600018497    steps: 173    lr: 0.0001     evaluation reward: 1.5\n",
            "episode: 783   score: 4.0   memory length: 143347   epsilon: 0.9141709600018633    steps: 315    lr: 0.0001     evaluation reward: 1.53\n",
            "episode: 784   score: 2.0   memory length: 143546   epsilon: 0.9137769400018718    steps: 199    lr: 0.0001     evaluation reward: 1.54\n",
            "episode: 785   score: 3.0   memory length: 143797   epsilon: 0.9132799600018826    steps: 251    lr: 0.0001     evaluation reward: 1.55\n",
            "episode: 786   score: 3.0   memory length: 144026   epsilon: 0.9128265400018925    steps: 229    lr: 0.0001     evaluation reward: 1.57\n",
            "episode: 787   score: 2.0   memory length: 144247   epsilon: 0.912388960001902    steps: 221    lr: 0.0001     evaluation reward: 1.58\n",
            "episode: 788   score: 2.0   memory length: 144466   epsilon: 0.9119553400019114    steps: 219    lr: 0.0001     evaluation reward: 1.6\n",
            "episode: 789   score: 1.0   memory length: 144618   epsilon: 0.9116543800019179    steps: 152    lr: 0.0001     evaluation reward: 1.61\n",
            "episode: 790   score: 2.0   memory length: 144838   epsilon: 0.9112187800019274    steps: 220    lr: 0.0001     evaluation reward: 1.63\n",
            "episode: 791   score: 0.0   memory length: 144962   epsilon: 0.9109732600019327    steps: 124    lr: 0.0001     evaluation reward: 1.58\n",
            "episode: 792   score: 0.0   memory length: 145086   epsilon: 0.910727740001938    steps: 124    lr: 0.0001     evaluation reward: 1.57\n",
            "episode: 793   score: 3.0   memory length: 145352   epsilon: 0.9102010600019494    steps: 266    lr: 0.0001     evaluation reward: 1.59\n",
            "episode: 794   score: 0.0   memory length: 145476   epsilon: 0.9099555400019548    steps: 124    lr: 0.0001     evaluation reward: 1.58\n",
            "episode: 795   score: 2.0   memory length: 145674   epsilon: 0.9095635000019633    steps: 198    lr: 0.0001     evaluation reward: 1.52\n",
            "episode: 796   score: 1.0   memory length: 145827   epsilon: 0.9092605600019699    steps: 153    lr: 0.0001     evaluation reward: 1.52\n",
            "episode: 797   score: 1.0   memory length: 145978   epsilon: 0.9089615800019764    steps: 151    lr: 0.0001     evaluation reward: 1.53\n",
            "episode: 798   score: 1.0   memory length: 146148   epsilon: 0.9086249800019837    steps: 170    lr: 0.0001     evaluation reward: 1.54\n",
            "episode: 799   score: 2.0   memory length: 146367   epsilon: 0.9081913600019931    steps: 219    lr: 0.0001     evaluation reward: 1.53\n",
            "episode: 800   score: 4.0   memory length: 146643   epsilon: 0.9076448800020049    steps: 276    lr: 0.0001     evaluation reward: 1.55\n",
            "episode: 801   score: 0.0   memory length: 146767   epsilon: 0.9073993600020103    steps: 124    lr: 0.0001     evaluation reward: 1.54\n",
            "episode: 802   score: 0.0   memory length: 146891   epsilon: 0.9071538400020156    steps: 124    lr: 0.0001     evaluation reward: 1.54\n",
            "episode: 803   score: 3.0   memory length: 147117   epsilon: 0.9067063600020253    steps: 226    lr: 0.0001     evaluation reward: 1.55\n",
            "episode: 804   score: 4.0   memory length: 147405   epsilon: 0.9061361200020377    steps: 288    lr: 0.0001     evaluation reward: 1.57\n",
            "episode: 805   score: 0.0   memory length: 147529   epsilon: 0.905890600002043    steps: 124    lr: 0.0001     evaluation reward: 1.57\n",
            "episode: 806   score: 1.0   memory length: 147699   epsilon: 0.9055540000020503    steps: 170    lr: 0.0001     evaluation reward: 1.56\n",
            "episode: 807   score: 0.0   memory length: 147823   epsilon: 0.9053084800020557    steps: 124    lr: 0.0001     evaluation reward: 1.56\n",
            "episode: 808   score: 0.0   memory length: 147947   epsilon: 0.905062960002061    steps: 124    lr: 0.0001     evaluation reward: 1.53\n",
            "episode: 809   score: 4.0   memory length: 148248   epsilon: 0.9044669800020739    steps: 301    lr: 0.0001     evaluation reward: 1.56\n",
            "episode: 810   score: 1.0   memory length: 148418   epsilon: 0.9041303800020812    steps: 170    lr: 0.0001     evaluation reward: 1.56\n",
            "episode: 811   score: 2.0   memory length: 148635   epsilon: 0.9037007200020906    steps: 217    lr: 0.0001     evaluation reward: 1.53\n",
            "episode: 812   score: 1.0   memory length: 148807   epsilon: 0.903360160002098    steps: 172    lr: 0.0001     evaluation reward: 1.51\n",
            "episode: 813   score: 2.0   memory length: 149027   epsilon: 0.9029245600021074    steps: 220    lr: 0.0001     evaluation reward: 1.51\n",
            "episode: 814   score: 2.0   memory length: 149225   epsilon: 0.9025325200021159    steps: 198    lr: 0.0001     evaluation reward: 1.51\n",
            "episode: 815   score: 1.0   memory length: 149377   epsilon: 0.9022315600021225    steps: 152    lr: 0.0001     evaluation reward: 1.51\n",
            "episode: 816   score: 3.0   memory length: 149603   epsilon: 0.9017840800021322    steps: 226    lr: 0.0001     evaluation reward: 1.54\n",
            "episode: 817   score: 0.0   memory length: 149727   epsilon: 0.9015385600021375    steps: 124    lr: 0.0001     evaluation reward: 1.54\n",
            "episode: 818   score: 1.0   memory length: 149900   epsilon: 0.9011960200021449    steps: 173    lr: 0.0001     evaluation reward: 1.53\n",
            "episode: 819   score: 3.0   memory length: 150129   epsilon: 0.9007426000021548    steps: 229    lr: 0.0001     evaluation reward: 1.55\n",
            "episode: 820   score: 3.0   memory length: 150373   epsilon: 0.9002594800021653    steps: 244    lr: 0.0001     evaluation reward: 1.56\n",
            "episode: 821   score: 5.0   memory length: 150670   epsilon: 0.899671420002178    steps: 297    lr: 0.0001     evaluation reward: 1.61\n",
            "episode: 822   score: 1.0   memory length: 150840   epsilon: 0.8993348200021853    steps: 170    lr: 0.0001     evaluation reward: 1.58\n",
            "episode: 823   score: 1.0   memory length: 150992   epsilon: 0.8990338600021919    steps: 152    lr: 0.0001     evaluation reward: 1.57\n",
            "episode: 824   score: 1.0   memory length: 151144   epsilon: 0.8987329000021984    steps: 152    lr: 0.0001     evaluation reward: 1.58\n",
            "episode: 825   score: 2.0   memory length: 151342   epsilon: 0.8983408600022069    steps: 198    lr: 0.0001     evaluation reward: 1.58\n",
            "episode: 826   score: 0.0   memory length: 151466   epsilon: 0.8980953400022123    steps: 124    lr: 0.0001     evaluation reward: 1.55\n",
            "episode: 827   score: 3.0   memory length: 151713   epsilon: 0.8976062800022229    steps: 247    lr: 0.0001     evaluation reward: 1.58\n",
            "episode: 828   score: 3.0   memory length: 151981   epsilon: 0.8970756400022344    steps: 268    lr: 0.0001     evaluation reward: 1.59\n",
            "episode: 829   score: 1.0   memory length: 152154   epsilon: 0.8967331000022418    steps: 173    lr: 0.0001     evaluation reward: 1.6\n",
            "episode: 830   score: 3.0   memory length: 152386   epsilon: 0.8962737400022518    steps: 232    lr: 0.0001     evaluation reward: 1.6\n",
            "episode: 831   score: 2.0   memory length: 152608   epsilon: 0.8958341800022613    steps: 222    lr: 0.0001     evaluation reward: 1.59\n",
            "episode: 832   score: 1.0   memory length: 152760   epsilon: 0.8955332200022679    steps: 152    lr: 0.0001     evaluation reward: 1.58\n",
            "episode: 833   score: 1.0   memory length: 152930   epsilon: 0.8951966200022752    steps: 170    lr: 0.0001     evaluation reward: 1.59\n",
            "episode: 834   score: 0.0   memory length: 153053   epsilon: 0.8949530800022805    steps: 123    lr: 0.0001     evaluation reward: 1.56\n",
            "episode: 835   score: 3.0   memory length: 153287   epsilon: 0.8944897600022905    steps: 234    lr: 0.0001     evaluation reward: 1.59\n",
            "episode: 836   score: 2.0   memory length: 153508   epsilon: 0.8940521800023    steps: 221    lr: 0.0001     evaluation reward: 1.61\n",
            "episode: 837   score: 1.0   memory length: 153679   epsilon: 0.8937136000023074    steps: 171    lr: 0.0001     evaluation reward: 1.61\n",
            "episode: 838   score: 2.0   memory length: 153877   epsilon: 0.8933215600023159    steps: 198    lr: 0.0001     evaluation reward: 1.63\n",
            "episode: 839   score: 3.0   memory length: 154121   epsilon: 0.8928384400023264    steps: 244    lr: 0.0001     evaluation reward: 1.66\n",
            "episode: 840   score: 0.0   memory length: 154245   epsilon: 0.8925929200023317    steps: 124    lr: 0.0001     evaluation reward: 1.64\n",
            "episode: 841   score: 0.0   memory length: 154368   epsilon: 0.892349380002337    steps: 123    lr: 0.0001     evaluation reward: 1.62\n",
            "episode: 842   score: 4.0   memory length: 154686   epsilon: 0.8917197400023507    steps: 318    lr: 0.0001     evaluation reward: 1.64\n",
            "episode: 843   score: 1.0   memory length: 154857   epsilon: 0.891381160002358    steps: 171    lr: 0.0001     evaluation reward: 1.65\n",
            "episode: 844   score: 0.0   memory length: 154980   epsilon: 0.8911376200023633    steps: 123    lr: 0.0001     evaluation reward: 1.65\n",
            "episode: 845   score: 3.0   memory length: 155207   epsilon: 0.890688160002373    steps: 227    lr: 0.0001     evaluation reward: 1.65\n",
            "episode: 846   score: 4.0   memory length: 155481   epsilon: 0.8901456400023848    steps: 274    lr: 0.0001     evaluation reward: 1.66\n",
            "episode: 847   score: 0.0   memory length: 155604   epsilon: 0.8899021000023901    steps: 123    lr: 0.0001     evaluation reward: 1.65\n",
            "episode: 848   score: 5.0   memory length: 155933   epsilon: 0.8892506800024043    steps: 329    lr: 0.0001     evaluation reward: 1.69\n",
            "episode: 849   score: 1.0   memory length: 156104   epsilon: 0.8889121000024116    steps: 171    lr: 0.0001     evaluation reward: 1.67\n",
            "episode: 850   score: 0.0   memory length: 156227   epsilon: 0.8886685600024169    steps: 123    lr: 0.0001     evaluation reward: 1.67\n",
            "episode: 851   score: 0.0   memory length: 156351   epsilon: 0.8884230400024222    steps: 124    lr: 0.0001     evaluation reward: 1.67\n",
            "episode: 852   score: 0.0   memory length: 156474   epsilon: 0.8881795000024275    steps: 123    lr: 0.0001     evaluation reward: 1.66\n",
            "episode: 853   score: 3.0   memory length: 156722   epsilon: 0.8876884600024382    steps: 248    lr: 0.0001     evaluation reward: 1.69\n",
            "episode: 854   score: 0.0   memory length: 156846   epsilon: 0.8874429400024435    steps: 124    lr: 0.0001     evaluation reward: 1.68\n",
            "episode: 855   score: 3.0   memory length: 157092   epsilon: 0.8869558600024541    steps: 246    lr: 0.0001     evaluation reward: 1.69\n",
            "episode: 856   score: 2.0   memory length: 157290   epsilon: 0.8865638200024626    steps: 198    lr: 0.0001     evaluation reward: 1.66\n",
            "episode: 857   score: 2.0   memory length: 157488   epsilon: 0.8861717800024711    steps: 198    lr: 0.0001     evaluation reward: 1.64\n",
            "episode: 858   score: 0.0   memory length: 157611   epsilon: 0.8859282400024764    steps: 123    lr: 0.0001     evaluation reward: 1.62\n",
            "episode: 859   score: 2.0   memory length: 157810   epsilon: 0.8855342200024849    steps: 199    lr: 0.0001     evaluation reward: 1.62\n",
            "episode: 860   score: 3.0   memory length: 158074   epsilon: 0.8850115000024963    steps: 264    lr: 0.0001     evaluation reward: 1.65\n",
            "episode: 861   score: 1.0   memory length: 158227   epsilon: 0.8847085600025029    steps: 153    lr: 0.0001     evaluation reward: 1.65\n",
            "episode: 862   score: 3.0   memory length: 158474   epsilon: 0.8842195000025135    steps: 247    lr: 0.0001     evaluation reward: 1.68\n",
            "episode: 863   score: 2.0   memory length: 158675   epsilon: 0.8838215200025221    steps: 201    lr: 0.0001     evaluation reward: 1.67\n",
            "episode: 864   score: 2.0   memory length: 158896   epsilon: 0.8833839400025316    steps: 221    lr: 0.0001     evaluation reward: 1.67\n",
            "episode: 865   score: 0.0   memory length: 159020   epsilon: 0.883138420002537    steps: 124    lr: 0.0001     evaluation reward: 1.67\n",
            "episode: 866   score: 1.0   memory length: 159190   epsilon: 0.8828018200025443    steps: 170    lr: 0.0001     evaluation reward: 1.65\n",
            "episode: 867   score: 3.0   memory length: 159458   epsilon: 0.8822711800025558    steps: 268    lr: 0.0001     evaluation reward: 1.67\n",
            "episode: 868   score: 5.0   memory length: 159803   epsilon: 0.8815880800025706    steps: 345    lr: 0.0001     evaluation reward: 1.7\n",
            "episode: 869   score: 4.0   memory length: 160079   epsilon: 0.8810416000025825    steps: 276    lr: 0.0001     evaluation reward: 1.73\n",
            "episode: 870   score: 4.0   memory length: 160399   epsilon: 0.8804080000025962    steps: 320    lr: 0.0001     evaluation reward: 1.75\n",
            "episode: 871   score: 3.0   memory length: 160647   epsilon: 0.8799169600026069    steps: 248    lr: 0.0001     evaluation reward: 1.78\n",
            "episode: 872   score: 1.0   memory length: 160799   epsilon: 0.8796160000026134    steps: 152    lr: 0.0001     evaluation reward: 1.78\n",
            "episode: 873   score: 1.0   memory length: 160969   epsilon: 0.8792794000026207    steps: 170    lr: 0.0001     evaluation reward: 1.77\n",
            "episode: 874   score: 1.0   memory length: 161121   epsilon: 0.8789784400026273    steps: 152    lr: 0.0001     evaluation reward: 1.76\n",
            "episode: 875   score: 2.0   memory length: 161320   epsilon: 0.8785844200026358    steps: 199    lr: 0.0001     evaluation reward: 1.76\n",
            "episode: 876   score: 1.0   memory length: 161472   epsilon: 0.8782834600026423    steps: 152    lr: 0.0001     evaluation reward: 1.75\n",
            "episode: 877   score: 2.0   memory length: 161691   epsilon: 0.8778498400026518    steps: 219    lr: 0.0001     evaluation reward: 1.74\n",
            "episode: 878   score: 2.0   memory length: 161890   epsilon: 0.8774558200026603    steps: 199    lr: 0.0001     evaluation reward: 1.76\n",
            "episode: 879   score: 0.0   memory length: 162014   epsilon: 0.8772103000026656    steps: 124    lr: 0.0001     evaluation reward: 1.76\n",
            "episode: 880   score: 1.0   memory length: 162184   epsilon: 0.876873700002673    steps: 170    lr: 0.0001     evaluation reward: 1.72\n",
            "episode: 881   score: 2.0   memory length: 162382   epsilon: 0.8764816600026815    steps: 198    lr: 0.0001     evaluation reward: 1.74\n",
            "episode: 882   score: 2.0   memory length: 162580   epsilon: 0.87608962000269    steps: 198    lr: 0.0001     evaluation reward: 1.75\n",
            "episode: 883   score: 2.0   memory length: 162800   epsilon: 0.8756540200026994    steps: 220    lr: 0.0001     evaluation reward: 1.73\n",
            "episode: 884   score: 0.0   memory length: 162924   epsilon: 0.8754085000027048    steps: 124    lr: 0.0001     evaluation reward: 1.71\n",
            "episode: 885   score: 0.0   memory length: 163048   epsilon: 0.8751629800027101    steps: 124    lr: 0.0001     evaluation reward: 1.68\n",
            "episode: 886   score: 1.0   memory length: 163219   epsilon: 0.8748244000027174    steps: 171    lr: 0.0001     evaluation reward: 1.66\n",
            "episode: 887   score: 2.0   memory length: 163418   epsilon: 0.874430380002726    steps: 199    lr: 0.0001     evaluation reward: 1.66\n",
            "episode: 888   score: 2.0   memory length: 163617   epsilon: 0.8740363600027345    steps: 199    lr: 0.0001     evaluation reward: 1.66\n",
            "episode: 889   score: 2.0   memory length: 163836   epsilon: 0.873602740002744    steps: 219    lr: 0.0001     evaluation reward: 1.67\n",
            "episode: 890   score: 2.0   memory length: 164055   epsilon: 0.8731691200027534    steps: 219    lr: 0.0001     evaluation reward: 1.67\n",
            "episode: 891   score: 4.0   memory length: 164351   epsilon: 0.8725830400027661    steps: 296    lr: 0.0001     evaluation reward: 1.71\n",
            "episode: 892   score: 4.0   memory length: 164647   epsilon: 0.8719969600027788    steps: 296    lr: 0.0001     evaluation reward: 1.75\n",
            "episode: 893   score: 2.0   memory length: 164846   epsilon: 0.8716029400027874    steps: 199    lr: 0.0001     evaluation reward: 1.74\n",
            "episode: 894   score: 2.0   memory length: 165044   epsilon: 0.8712109000027959    steps: 198    lr: 0.0001     evaluation reward: 1.76\n",
            "episode: 895   score: 4.0   memory length: 165338   epsilon: 0.8706287800028085    steps: 294    lr: 0.0001     evaluation reward: 1.78\n",
            "episode: 896   score: 2.0   memory length: 165556   epsilon: 0.8701971400028179    steps: 218    lr: 0.0001     evaluation reward: 1.79\n",
            "episode: 897   score: 2.0   memory length: 165775   epsilon: 0.8697635200028273    steps: 219    lr: 0.0001     evaluation reward: 1.8\n",
            "episode: 898   score: 1.0   memory length: 165927   epsilon: 0.8694625600028338    steps: 152    lr: 0.0001     evaluation reward: 1.8\n",
            "episode: 899   score: 3.0   memory length: 166176   epsilon: 0.8689695400028445    steps: 249    lr: 0.0001     evaluation reward: 1.81\n",
            "episode: 900   score: 2.0   memory length: 166375   epsilon: 0.8685755200028531    steps: 199    lr: 0.0001     evaluation reward: 1.79\n",
            "episode: 901   score: 2.0   memory length: 166573   epsilon: 0.8681834800028616    steps: 198    lr: 0.0001     evaluation reward: 1.81\n",
            "episode: 902   score: 4.0   memory length: 166870   epsilon: 0.8675954200028744    steps: 297    lr: 0.0001     evaluation reward: 1.85\n",
            "episode: 903   score: 2.0   memory length: 167069   epsilon: 0.8672014000028829    steps: 199    lr: 0.0001     evaluation reward: 1.84\n",
            "episode: 904   score: 1.0   memory length: 167221   epsilon: 0.8669004400028895    steps: 152    lr: 0.0001     evaluation reward: 1.81\n",
            "episode: 905   score: 1.0   memory length: 167392   epsilon: 0.8665618600028968    steps: 171    lr: 0.0001     evaluation reward: 1.82\n",
            "episode: 906   score: 0.0   memory length: 167515   epsilon: 0.8663183200029021    steps: 123    lr: 0.0001     evaluation reward: 1.81\n",
            "episode: 907   score: 4.0   memory length: 167793   epsilon: 0.865767880002914    steps: 278    lr: 0.0001     evaluation reward: 1.85\n",
            "episode: 908   score: 1.0   memory length: 167946   epsilon: 0.8654649400029206    steps: 153    lr: 0.0001     evaluation reward: 1.86\n",
            "episode: 909   score: 0.0   memory length: 168069   epsilon: 0.8652214000029259    steps: 123    lr: 0.0001     evaluation reward: 1.82\n",
            "episode: 910   score: 3.0   memory length: 168316   epsilon: 0.8647323400029365    steps: 247    lr: 0.0001     evaluation reward: 1.84\n",
            "episode: 911   score: 3.0   memory length: 168545   epsilon: 0.8642789200029464    steps: 229    lr: 0.0001     evaluation reward: 1.85\n",
            "episode: 912   score: 0.0   memory length: 168669   epsilon: 0.8640334000029517    steps: 124    lr: 0.0001     evaluation reward: 1.84\n",
            "episode: 913   score: 3.0   memory length: 168896   epsilon: 0.8635839400029615    steps: 227    lr: 0.0001     evaluation reward: 1.85\n",
            "episode: 914   score: 1.0   memory length: 169048   epsilon: 0.863282980002968    steps: 152    lr: 0.0001     evaluation reward: 1.84\n",
            "episode: 915   score: 7.0   memory length: 169349   epsilon: 0.8626870000029809    steps: 301    lr: 0.0001     evaluation reward: 1.9\n",
            "episode: 916   score: 3.0   memory length: 169597   epsilon: 0.8621959600029916    steps: 248    lr: 0.0001     evaluation reward: 1.9\n",
            "episode: 917   score: 2.0   memory length: 169782   epsilon: 0.8618296600029995    steps: 185    lr: 0.0001     evaluation reward: 1.92\n",
            "episode: 918   score: 1.0   memory length: 169952   epsilon: 0.8614930600030068    steps: 170    lr: 0.0001     evaluation reward: 1.92\n",
            "episode: 919   score: 3.0   memory length: 170200   epsilon: 0.8610020200030175    steps: 248    lr: 0.0001     evaluation reward: 1.92\n",
            "episode: 920   score: 1.0   memory length: 170371   epsilon: 0.8606634400030249    steps: 171    lr: 0.0001     evaluation reward: 1.9\n",
            "episode: 921   score: 2.0   memory length: 170592   epsilon: 0.8602258600030344    steps: 221    lr: 0.0001     evaluation reward: 1.87\n",
            "episode: 922   score: 1.0   memory length: 170762   epsilon: 0.8598892600030417    steps: 170    lr: 0.0001     evaluation reward: 1.87\n",
            "episode: 923   score: 2.0   memory length: 170961   epsilon: 0.8594952400030502    steps: 199    lr: 0.0001     evaluation reward: 1.88\n",
            "episode: 924   score: 0.0   memory length: 171084   epsilon: 0.8592517000030555    steps: 123    lr: 0.0001     evaluation reward: 1.87\n",
            "episode: 925   score: 1.0   memory length: 171254   epsilon: 0.8589151000030628    steps: 170    lr: 0.0001     evaluation reward: 1.86\n",
            "episode: 926   score: 0.0   memory length: 171378   epsilon: 0.8586695800030681    steps: 124    lr: 0.0001     evaluation reward: 1.86\n",
            "episode: 927   score: 0.0   memory length: 171501   epsilon: 0.8584260400030734    steps: 123    lr: 0.0001     evaluation reward: 1.83\n",
            "episode: 928   score: 3.0   memory length: 171731   epsilon: 0.8579706400030833    steps: 230    lr: 0.0001     evaluation reward: 1.83\n",
            "episode: 929   score: 2.0   memory length: 171930   epsilon: 0.8575766200030919    steps: 199    lr: 0.0001     evaluation reward: 1.84\n",
            "episode: 930   score: 3.0   memory length: 172175   epsilon: 0.8570915200031024    steps: 245    lr: 0.0001     evaluation reward: 1.84\n",
            "episode: 931   score: 1.0   memory length: 172327   epsilon: 0.8567905600031089    steps: 152    lr: 0.0001     evaluation reward: 1.83\n",
            "episode: 932   score: 1.0   memory length: 172497   epsilon: 0.8564539600031162    steps: 170    lr: 0.0001     evaluation reward: 1.83\n",
            "episode: 933   score: 0.0   memory length: 172620   epsilon: 0.8562104200031215    steps: 123    lr: 0.0001     evaluation reward: 1.82\n",
            "episode: 934   score: 1.0   memory length: 172771   epsilon: 0.855911440003128    steps: 151    lr: 0.0001     evaluation reward: 1.83\n",
            "episode: 935   score: 2.0   memory length: 172990   epsilon: 0.8554778200031374    steps: 219    lr: 0.0001     evaluation reward: 1.82\n",
            "episode: 936   score: 1.0   memory length: 173159   epsilon: 0.8551432000031447    steps: 169    lr: 0.0001     evaluation reward: 1.81\n",
            "episode: 937   score: 4.0   memory length: 173417   epsilon: 0.8546323600031558    steps: 258    lr: 0.0001     evaluation reward: 1.84\n",
            "episode: 938   score: 2.0   memory length: 173616   epsilon: 0.8542383400031643    steps: 199    lr: 0.0001     evaluation reward: 1.84\n",
            "episode: 939   score: 4.0   memory length: 173912   epsilon: 0.8536522600031771    steps: 296    lr: 0.0001     evaluation reward: 1.85\n",
            "episode: 940   score: 1.0   memory length: 174063   epsilon: 0.8533532800031836    steps: 151    lr: 0.0001     evaluation reward: 1.86\n",
            "episode: 941   score: 3.0   memory length: 174289   epsilon: 0.8529058000031933    steps: 226    lr: 0.0001     evaluation reward: 1.89\n",
            "episode: 942   score: 0.0   memory length: 174412   epsilon: 0.8526622600031986    steps: 123    lr: 0.0001     evaluation reward: 1.85\n",
            "episode: 943   score: 2.0   memory length: 174611   epsilon: 0.8522682400032071    steps: 199    lr: 0.0001     evaluation reward: 1.86\n",
            "episode: 944   score: 0.0   memory length: 174735   epsilon: 0.8520227200032124    steps: 124    lr: 0.0001     evaluation reward: 1.86\n",
            "episode: 945   score: 1.0   memory length: 174887   epsilon: 0.851721760003219    steps: 152    lr: 0.0001     evaluation reward: 1.84\n",
            "episode: 946   score: 3.0   memory length: 175135   epsilon: 0.8512307200032296    steps: 248    lr: 0.0001     evaluation reward: 1.83\n",
            "episode: 947   score: 0.0   memory length: 175258   epsilon: 0.8509871800032349    steps: 123    lr: 0.0001     evaluation reward: 1.83\n",
            "episode: 948   score: 1.0   memory length: 175430   epsilon: 0.8506466200032423    steps: 172    lr: 0.0001     evaluation reward: 1.79\n",
            "episode: 949   score: 2.0   memory length: 175648   epsilon: 0.8502149800032517    steps: 218    lr: 0.0001     evaluation reward: 1.8\n",
            "episode: 950   score: 3.0   memory length: 175896   epsilon: 0.8497239400032623    steps: 248    lr: 0.0001     evaluation reward: 1.83\n",
            "episode: 951   score: 2.0   memory length: 176095   epsilon: 0.8493299200032709    steps: 199    lr: 0.0001     evaluation reward: 1.85\n",
            "episode: 952   score: 1.0   memory length: 176264   epsilon: 0.8489953000032782    steps: 169    lr: 0.0001     evaluation reward: 1.86\n",
            "episode: 953   score: 1.0   memory length: 176434   epsilon: 0.8486587000032855    steps: 170    lr: 0.0001     evaluation reward: 1.84\n",
            "episode: 954   score: 3.0   memory length: 176705   epsilon: 0.8481221200032971    steps: 271    lr: 0.0001     evaluation reward: 1.87\n",
            "episode: 955   score: 0.0   memory length: 176829   epsilon: 0.8478766000033024    steps: 124    lr: 0.0001     evaluation reward: 1.84\n",
            "episode: 956   score: 0.0   memory length: 176953   epsilon: 0.8476310800033078    steps: 124    lr: 0.0001     evaluation reward: 1.82\n",
            "episode: 957   score: 2.0   memory length: 177152   epsilon: 0.8472370600033163    steps: 199    lr: 0.0001     evaluation reward: 1.82\n",
            "episode: 958   score: 2.0   memory length: 177353   epsilon: 0.846839080003325    steps: 201    lr: 0.0001     evaluation reward: 1.84\n",
            "episode: 959   score: 0.0   memory length: 177477   epsilon: 0.8465935600033303    steps: 124    lr: 0.0001     evaluation reward: 1.82\n",
            "episode: 960   score: 4.0   memory length: 177754   epsilon: 0.8460451000033422    steps: 277    lr: 0.0001     evaluation reward: 1.83\n",
            "episode: 961   score: 1.0   memory length: 177924   epsilon: 0.8457085000033495    steps: 170    lr: 0.0001     evaluation reward: 1.83\n",
            "episode: 962   score: 0.0   memory length: 178048   epsilon: 0.8454629800033548    steps: 124    lr: 0.0001     evaluation reward: 1.8\n",
            "episode: 963   score: 2.0   memory length: 178265   epsilon: 0.8450333200033642    steps: 217    lr: 0.0001     evaluation reward: 1.8\n",
            "episode: 964   score: 4.0   memory length: 178552   epsilon: 0.8444650600033765    steps: 287    lr: 0.0001     evaluation reward: 1.82\n",
            "episode: 965   score: 1.0   memory length: 178722   epsilon: 0.8441284600033838    steps: 170    lr: 0.0001     evaluation reward: 1.83\n",
            "episode: 966   score: 0.0   memory length: 178846   epsilon: 0.8438829400033891    steps: 124    lr: 0.0001     evaluation reward: 1.82\n",
            "episode: 967   score: 0.0   memory length: 178970   epsilon: 0.8436374200033945    steps: 124    lr: 0.0001     evaluation reward: 1.79\n",
            "episode: 968   score: 0.0   memory length: 179094   epsilon: 0.8433919000033998    steps: 124    lr: 0.0001     evaluation reward: 1.74\n",
            "episode: 969   score: 4.0   memory length: 179390   epsilon: 0.8428058200034125    steps: 296    lr: 0.0001     evaluation reward: 1.74\n",
            "episode: 970   score: 3.0   memory length: 179636   epsilon: 0.8423187400034231    steps: 246    lr: 0.0001     evaluation reward: 1.73\n",
            "episode: 971   score: 3.0   memory length: 179905   epsilon: 0.8417861200034347    steps: 269    lr: 0.0001     evaluation reward: 1.73\n",
            "episode: 972   score: 1.0   memory length: 180075   epsilon: 0.841449520003442    steps: 170    lr: 0.0001     evaluation reward: 1.73\n",
            "episode: 973   score: 4.0   memory length: 180377   epsilon: 0.840851560003455    steps: 302    lr: 0.0001     evaluation reward: 1.76\n",
            "episode: 974   score: 6.0   memory length: 180759   epsilon: 0.8400952000034714    steps: 382    lr: 0.0001     evaluation reward: 1.81\n",
            "episode: 975   score: 5.0   memory length: 181104   epsilon: 0.8394121000034862    steps: 345    lr: 0.0001     evaluation reward: 1.84\n",
            "episode: 976   score: 2.0   memory length: 181324   epsilon: 0.8389765000034957    steps: 220    lr: 0.0001     evaluation reward: 1.85\n",
            "episode: 977   score: 2.0   memory length: 181522   epsilon: 0.8385844600035042    steps: 198    lr: 0.0001     evaluation reward: 1.85\n",
            "episode: 978   score: 1.0   memory length: 181695   epsilon: 0.8382419200035116    steps: 173    lr: 0.0001     evaluation reward: 1.84\n",
            "episode: 979   score: 1.0   memory length: 181865   epsilon: 0.8379053200035189    steps: 170    lr: 0.0001     evaluation reward: 1.85\n",
            "episode: 980   score: 3.0   memory length: 182111   epsilon: 0.8374182400035295    steps: 246    lr: 0.0001     evaluation reward: 1.87\n",
            "episode: 981   score: 0.0   memory length: 182234   epsilon: 0.8371747000035348    steps: 123    lr: 0.0001     evaluation reward: 1.85\n",
            "episode: 982   score: 2.0   memory length: 182451   epsilon: 0.8367450400035441    steps: 217    lr: 0.0001     evaluation reward: 1.85\n",
            "episode: 983   score: 1.0   memory length: 182621   epsilon: 0.8364084400035514    steps: 170    lr: 0.0001     evaluation reward: 1.84\n",
            "episode: 984   score: 0.0   memory length: 182745   epsilon: 0.8361629200035567    steps: 124    lr: 0.0001     evaluation reward: 1.84\n",
            "episode: 985   score: 5.0   memory length: 183084   epsilon: 0.8354917000035713    steps: 339    lr: 0.0001     evaluation reward: 1.89\n",
            "episode: 986   score: 2.0   memory length: 183283   epsilon: 0.8350976800035799    steps: 199    lr: 0.0001     evaluation reward: 1.9\n",
            "episode: 987   score: 4.0   memory length: 183577   epsilon: 0.8345155600035925    steps: 294    lr: 0.0001     evaluation reward: 1.92\n",
            "episode: 988   score: 1.0   memory length: 183748   epsilon: 0.8341769800035999    steps: 171    lr: 0.0001     evaluation reward: 1.91\n",
            "episode: 989   score: 0.0   memory length: 183872   epsilon: 0.8339314600036052    steps: 124    lr: 0.0001     evaluation reward: 1.89\n",
            "episode: 990   score: 2.0   memory length: 184070   epsilon: 0.8335394200036137    steps: 198    lr: 0.0001     evaluation reward: 1.89\n",
            "episode: 991   score: 2.0   memory length: 184269   epsilon: 0.8331454000036222    steps: 199    lr: 0.0001     evaluation reward: 1.87\n",
            "episode: 992   score: 5.0   memory length: 184579   epsilon: 0.8325316000036356    steps: 310    lr: 0.0001     evaluation reward: 1.88\n",
            "episode: 993   score: 3.0   memory length: 184827   epsilon: 0.8320405600036462    steps: 248    lr: 0.0001     evaluation reward: 1.89\n",
            "episode: 994   score: 2.0   memory length: 185047   epsilon: 0.8316049600036557    steps: 220    lr: 0.0001     evaluation reward: 1.89\n",
            "episode: 995   score: 1.0   memory length: 185199   epsilon: 0.8313040000036622    steps: 152    lr: 0.0001     evaluation reward: 1.86\n",
            "episode: 996   score: 2.0   memory length: 185398   epsilon: 0.8309099800036708    steps: 199    lr: 0.0001     evaluation reward: 1.86\n",
            "episode: 997   score: 3.0   memory length: 185649   epsilon: 0.8304130000036816    steps: 251    lr: 0.0001     evaluation reward: 1.87\n",
            "episode: 998   score: 0.0   memory length: 185772   epsilon: 0.8301694600036869    steps: 123    lr: 0.0001     evaluation reward: 1.86\n",
            "episode: 999   score: 4.0   memory length: 186087   epsilon: 0.8295457600037004    steps: 315    lr: 0.0001     evaluation reward: 1.87\n",
            "episode: 1000   score: 2.0   memory length: 186286   epsilon: 0.829151740003709    steps: 199    lr: 0.0001     evaluation reward: 1.87\n",
            "episode: 1001   score: 2.0   memory length: 186507   epsilon: 0.8287141600037184    steps: 221    lr: 0.0001     evaluation reward: 1.87\n",
            "episode: 1002   score: 2.0   memory length: 186707   epsilon: 0.828318160003727    steps: 200    lr: 0.0001     evaluation reward: 1.85\n",
            "episode: 1003   score: 2.0   memory length: 186925   epsilon: 0.8278865200037364    steps: 218    lr: 0.0001     evaluation reward: 1.85\n",
            "episode: 1004   score: 0.0   memory length: 187048   epsilon: 0.8276429800037417    steps: 123    lr: 0.0001     evaluation reward: 1.84\n",
            "episode: 1005   score: 2.0   memory length: 187246   epsilon: 0.8272509400037502    steps: 198    lr: 0.0001     evaluation reward: 1.85\n",
            "episode: 1006   score: 0.0   memory length: 187369   epsilon: 0.8270074000037555    steps: 123    lr: 0.0001     evaluation reward: 1.85\n",
            "episode: 1007   score: 4.0   memory length: 187664   epsilon: 0.8264233000037682    steps: 295    lr: 0.0001     evaluation reward: 1.85\n",
            "episode: 1008   score: 2.0   memory length: 187885   epsilon: 0.8259857200037777    steps: 221    lr: 0.0001     evaluation reward: 1.86\n",
            "episode: 1009   score: 1.0   memory length: 188037   epsilon: 0.8256847600037842    steps: 152    lr: 0.0001     evaluation reward: 1.87\n",
            "episode: 1010   score: 0.0   memory length: 188161   epsilon: 0.8254392400037895    steps: 124    lr: 0.0001     evaluation reward: 1.84\n",
            "episode: 1011   score: 5.0   memory length: 188491   epsilon: 0.8247858400038037    steps: 330    lr: 0.0001     evaluation reward: 1.86\n",
            "episode: 1012   score: 0.0   memory length: 188615   epsilon: 0.8245403200038091    steps: 124    lr: 0.0001     evaluation reward: 1.86\n",
            "episode: 1013   score: 2.0   memory length: 188814   epsilon: 0.8241463000038176    steps: 199    lr: 0.0001     evaluation reward: 1.85\n",
            "episode: 1014   score: 2.0   memory length: 189033   epsilon: 0.823712680003827    steps: 219    lr: 0.0001     evaluation reward: 1.86\n",
            "episode: 1015   score: 2.0   memory length: 189235   epsilon: 0.8233127200038357    steps: 202    lr: 0.0001     evaluation reward: 1.81\n",
            "episode: 1016   score: 0.0   memory length: 189359   epsilon: 0.823067200003841    steps: 124    lr: 0.0001     evaluation reward: 1.78\n",
            "episode: 1017   score: 0.0   memory length: 189482   epsilon: 0.8228236600038463    steps: 123    lr: 0.0001     evaluation reward: 1.76\n",
            "episode: 1018   score: 0.0   memory length: 189605   epsilon: 0.8225801200038516    steps: 123    lr: 0.0001     evaluation reward: 1.75\n",
            "episode: 1019   score: 2.0   memory length: 189804   epsilon: 0.8221861000038602    steps: 199    lr: 0.0001     evaluation reward: 1.74\n",
            "episode: 1020   score: 0.0   memory length: 189928   epsilon: 0.8219405800038655    steps: 124    lr: 0.0001     evaluation reward: 1.73\n",
            "episode: 1021   score: 1.0   memory length: 190080   epsilon: 0.821639620003872    steps: 152    lr: 0.0001     evaluation reward: 1.72\n",
            "episode: 1022   score: 3.0   memory length: 190326   epsilon: 0.8211525400038826    steps: 246    lr: 0.0001     evaluation reward: 1.74\n",
            "episode: 1023   score: 1.0   memory length: 190496   epsilon: 0.8208159400038899    steps: 170    lr: 0.0001     evaluation reward: 1.73\n",
            "episode: 1024   score: 4.0   memory length: 190776   epsilon: 0.820261540003902    steps: 280    lr: 0.0001     evaluation reward: 1.77\n",
            "episode: 1025   score: 2.0   memory length: 190974   epsilon: 0.8198695000039105    steps: 198    lr: 0.0001     evaluation reward: 1.78\n",
            "episode: 1026   score: 2.0   memory length: 191172   epsilon: 0.819477460003919    steps: 198    lr: 0.0001     evaluation reward: 1.8\n",
            "episode: 1027   score: 0.0   memory length: 191295   epsilon: 0.8192339200039243    steps: 123    lr: 0.0001     evaluation reward: 1.8\n",
            "episode: 1028   score: 5.0   memory length: 191604   epsilon: 0.8186221000039375    steps: 309    lr: 0.0001     evaluation reward: 1.82\n",
            "episode: 1029   score: 2.0   memory length: 191822   epsilon: 0.8181904600039469    steps: 218    lr: 0.0001     evaluation reward: 1.82\n",
            "episode: 1030   score: 1.0   memory length: 191992   epsilon: 0.8178538600039542    steps: 170    lr: 0.0001     evaluation reward: 1.8\n",
            "episode: 1031   score: 3.0   memory length: 192237   epsilon: 0.8173687600039647    steps: 245    lr: 0.0001     evaluation reward: 1.82\n",
            "episode: 1032   score: 2.0   memory length: 192435   epsilon: 0.8169767200039733    steps: 198    lr: 0.0001     evaluation reward: 1.83\n",
            "episode: 1033   score: 2.0   memory length: 192652   epsilon: 0.8165470600039826    steps: 217    lr: 0.0001     evaluation reward: 1.85\n",
            "episode: 1034   score: 3.0   memory length: 192899   epsilon: 0.8160580000039932    steps: 247    lr: 0.0001     evaluation reward: 1.87\n",
            "episode: 1035   score: 2.0   memory length: 193098   epsilon: 0.8156639800040018    steps: 199    lr: 0.0001     evaluation reward: 1.87\n",
            "episode: 1036   score: 2.0   memory length: 193297   epsilon: 0.8152699600040103    steps: 199    lr: 0.0001     evaluation reward: 1.88\n",
            "episode: 1037   score: 7.0   memory length: 193598   epsilon: 0.8146739800040232    steps: 301    lr: 0.0001     evaluation reward: 1.91\n",
            "episode: 1038   score: 3.0   memory length: 193846   epsilon: 0.8141829400040339    steps: 248    lr: 0.0001     evaluation reward: 1.92\n",
            "episode: 1039   score: 3.0   memory length: 194117   epsilon: 0.8136463600040456    steps: 271    lr: 0.0001     evaluation reward: 1.91\n",
            "episode: 1040   score: 3.0   memory length: 194364   epsilon: 0.8131573000040562    steps: 247    lr: 0.0001     evaluation reward: 1.93\n",
            "episode: 1041   score: 2.0   memory length: 194563   epsilon: 0.8127632800040647    steps: 199    lr: 0.0001     evaluation reward: 1.92\n",
            "episode: 1042   score: 1.0   memory length: 194715   epsilon: 0.8124623200040713    steps: 152    lr: 0.0001     evaluation reward: 1.93\n",
            "episode: 1043   score: 3.0   memory length: 194945   epsilon: 0.8120069200040811    steps: 230    lr: 0.0001     evaluation reward: 1.94\n",
            "episode: 1044   score: 2.0   memory length: 195145   epsilon: 0.8116109200040897    steps: 200    lr: 0.0001     evaluation reward: 1.96\n",
            "episode: 1045   score: 0.0   memory length: 195269   epsilon: 0.8113654000040951    steps: 124    lr: 0.0001     evaluation reward: 1.95\n",
            "episode: 1046   score: 0.0   memory length: 195392   epsilon: 0.8111218600041004    steps: 123    lr: 0.0001     evaluation reward: 1.92\n",
            "episode: 1047   score: 2.0   memory length: 195608   epsilon: 0.8106941800041096    steps: 216    lr: 0.0001     evaluation reward: 1.94\n",
            "episode: 1048   score: 0.0   memory length: 195732   epsilon: 0.810448660004115    steps: 124    lr: 0.0001     evaluation reward: 1.93\n",
            "episode: 1049   score: 2.0   memory length: 195951   epsilon: 0.8100150400041244    steps: 219    lr: 0.0001     evaluation reward: 1.93\n",
            "episode: 1050   score: 0.0   memory length: 196075   epsilon: 0.8097695200041297    steps: 124    lr: 0.0001     evaluation reward: 1.9\n",
            "episode: 1051   score: 2.0   memory length: 196273   epsilon: 0.8093774800041382    steps: 198    lr: 0.0001     evaluation reward: 1.9\n",
            "episode: 1052   score: 1.0   memory length: 196443   epsilon: 0.8090408800041455    steps: 170    lr: 0.0001     evaluation reward: 1.9\n",
            "episode: 1053   score: 1.0   memory length: 196613   epsilon: 0.8087042800041528    steps: 170    lr: 0.0001     evaluation reward: 1.9\n",
            "episode: 1054   score: 2.0   memory length: 196812   epsilon: 0.8083102600041614    steps: 199    lr: 0.0001     evaluation reward: 1.89\n",
            "episode: 1055   score: 0.0   memory length: 196936   epsilon: 0.8080647400041667    steps: 124    lr: 0.0001     evaluation reward: 1.89\n",
            "episode: 1056   score: 0.0   memory length: 197060   epsilon: 0.8078192200041721    steps: 124    lr: 0.0001     evaluation reward: 1.89\n",
            "episode: 1057   score: 1.0   memory length: 197212   epsilon: 0.8075182600041786    steps: 152    lr: 0.0001     evaluation reward: 1.88\n",
            "episode: 1058   score: 3.0   memory length: 197438   epsilon: 0.8070707800041883    steps: 226    lr: 0.0001     evaluation reward: 1.89\n",
            "episode: 1059   score: 4.0   memory length: 197713   epsilon: 0.8065262800042001    steps: 275    lr: 0.0001     evaluation reward: 1.93\n",
            "episode: 1060   score: 0.0   memory length: 197837   epsilon: 0.8062807600042055    steps: 124    lr: 0.0001     evaluation reward: 1.89\n",
            "episode: 1061   score: 1.0   memory length: 198006   epsilon: 0.8059461400042127    steps: 169    lr: 0.0001     evaluation reward: 1.89\n",
            "episode: 1062   score: 5.0   memory length: 198316   epsilon: 0.805332340004226    steps: 310    lr: 0.0001     evaluation reward: 1.94\n",
            "episode: 1063   score: 5.0   memory length: 198653   epsilon: 0.8046650800042405    steps: 337    lr: 0.0001     evaluation reward: 1.97\n",
            "episode: 1064   score: 2.0   memory length: 198852   epsilon: 0.8042710600042491    steps: 199    lr: 0.0001     evaluation reward: 1.95\n",
            "episode: 1065   score: 0.0   memory length: 198975   epsilon: 0.8040275200042544    steps: 123    lr: 0.0001     evaluation reward: 1.94\n",
            "episode: 1066   score: 4.0   memory length: 199266   epsilon: 0.8034513400042669    steps: 291    lr: 0.0001     evaluation reward: 1.98\n",
            "episode: 1067   score: 1.0   memory length: 199418   epsilon: 0.8031503800042734    steps: 152    lr: 0.0001     evaluation reward: 1.99\n",
            "episode: 1068   score: 3.0   memory length: 199645   epsilon: 0.8027009200042832    steps: 227    lr: 0.0001     evaluation reward: 2.02\n",
            "episode: 1069   score: 2.0   memory length: 199844   epsilon: 0.8023069000042917    steps: 199    lr: 0.0001     evaluation reward: 2.0\n",
            "episode: 1070   score: 2.0   memory length: 200063   epsilon: 0.8018732800043011    steps: 219    lr: 4e-05     evaluation reward: 1.99\n",
            "episode: 1071   score: 2.0   memory length: 200280   epsilon: 0.8014436200043105    steps: 217    lr: 4e-05     evaluation reward: 1.98\n",
            "episode: 1072   score: 4.0   memory length: 200577   epsilon: 0.8008555600043232    steps: 297    lr: 4e-05     evaluation reward: 2.01\n",
            "episode: 1073   score: 4.0   memory length: 200853   epsilon: 0.8003090800043351    steps: 276    lr: 4e-05     evaluation reward: 2.01\n",
            "episode: 1074   score: 2.0   memory length: 201072   epsilon: 0.7998754600043445    steps: 219    lr: 4e-05     evaluation reward: 1.97\n",
            "episode: 1075   score: 2.0   memory length: 201291   epsilon: 0.7994418400043539    steps: 219    lr: 4e-05     evaluation reward: 1.94\n",
            "episode: 1076   score: 2.0   memory length: 201510   epsilon: 0.7990082200043633    steps: 219    lr: 4e-05     evaluation reward: 1.94\n",
            "episode: 1077   score: 2.0   memory length: 201709   epsilon: 0.7986142000043719    steps: 199    lr: 4e-05     evaluation reward: 1.94\n",
            "episode: 1078   score: 1.0   memory length: 201881   epsilon: 0.7982736400043793    steps: 172    lr: 4e-05     evaluation reward: 1.94\n",
            "episode: 1079   score: 0.0   memory length: 202005   epsilon: 0.7980281200043846    steps: 124    lr: 4e-05     evaluation reward: 1.93\n",
            "episode: 1080   score: 3.0   memory length: 202271   epsilon: 0.797501440004396    steps: 266    lr: 4e-05     evaluation reward: 1.93\n",
            "episode: 1081   score: 3.0   memory length: 202519   epsilon: 0.7970104000044067    steps: 248    lr: 4e-05     evaluation reward: 1.96\n",
            "episode: 1082   score: 3.0   memory length: 202746   epsilon: 0.7965609400044165    steps: 227    lr: 4e-05     evaluation reward: 1.97\n",
            "episode: 1083   score: 1.0   memory length: 202915   epsilon: 0.7962263200044237    steps: 169    lr: 4e-05     evaluation reward: 1.97\n",
            "episode: 1084   score: 1.0   memory length: 203087   epsilon: 0.7958857600044311    steps: 172    lr: 4e-05     evaluation reward: 1.98\n",
            "episode: 1085   score: 2.0   memory length: 203286   epsilon: 0.7954917400044397    steps: 199    lr: 4e-05     evaluation reward: 1.95\n",
            "episode: 1086   score: 4.0   memory length: 203582   epsilon: 0.7949056600044524    steps: 296    lr: 4e-05     evaluation reward: 1.97\n",
            "episode: 1087   score: 3.0   memory length: 203810   epsilon: 0.7944542200044622    steps: 228    lr: 4e-05     evaluation reward: 1.96\n",
            "episode: 1088   score: 1.0   memory length: 203962   epsilon: 0.7941532600044687    steps: 152    lr: 4e-05     evaluation reward: 1.96\n",
            "episode: 1089   score: 3.0   memory length: 204189   epsilon: 0.7937038000044785    steps: 227    lr: 4e-05     evaluation reward: 1.99\n",
            "episode: 1090   score: 0.0   memory length: 204313   epsilon: 0.7934582800044838    steps: 124    lr: 4e-05     evaluation reward: 1.97\n",
            "episode: 1091   score: 3.0   memory length: 204540   epsilon: 0.7930088200044936    steps: 227    lr: 4e-05     evaluation reward: 1.98\n",
            "episode: 1092   score: 5.0   memory length: 204879   epsilon: 0.7923376000045081    steps: 339    lr: 4e-05     evaluation reward: 1.98\n",
            "episode: 1093   score: 2.0   memory length: 205078   epsilon: 0.7919435800045167    steps: 199    lr: 4e-05     evaluation reward: 1.97\n",
            "episode: 1094   score: 2.0   memory length: 205298   epsilon: 0.7915079800045262    steps: 220    lr: 4e-05     evaluation reward: 1.97\n",
            "episode: 1095   score: 3.0   memory length: 205547   epsilon: 0.7910149600045369    steps: 249    lr: 4e-05     evaluation reward: 1.99\n",
            "episode: 1096   score: 1.0   memory length: 205699   epsilon: 0.7907140000045434    steps: 152    lr: 4e-05     evaluation reward: 1.98\n",
            "episode: 1097   score: 4.0   memory length: 205995   epsilon: 0.7901279200045561    steps: 296    lr: 4e-05     evaluation reward: 1.99\n",
            "episode: 1098   score: 5.0   memory length: 206332   epsilon: 0.7894606600045706    steps: 337    lr: 4e-05     evaluation reward: 2.04\n",
            "episode: 1099   score: 3.0   memory length: 206579   epsilon: 0.7889716000045812    steps: 247    lr: 4e-05     evaluation reward: 2.03\n",
            "episode: 1100   score: 3.0   memory length: 206827   epsilon: 0.7884805600045919    steps: 248    lr: 4e-05     evaluation reward: 2.04\n",
            "episode: 1101   score: 3.0   memory length: 207054   epsilon: 0.7880311000046016    steps: 227    lr: 4e-05     evaluation reward: 2.05\n",
            "episode: 1102   score: 2.0   memory length: 207235   epsilon: 0.7876727200046094    steps: 181    lr: 4e-05     evaluation reward: 2.05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2L7t07yM4YGe"
      },
      "source": [
        "## Training data for DQN "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "okZwNQGh4YGf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 653
        },
        "outputId": "d18cdff9-bd15-4293-8f5b-6923c14a26bd"
      },
      "source": [
        "\n",
        "import matplotlib.image as mpimg\n",
        "fig = plt.figure(figsize=(8,8))\n",
        "ax = fig.add_axes([0, 0, 1, 1], frameon=False)\n",
        "ax.margins(0)\n",
        "ax.set_xticks([])\n",
        "ax.set_yticks([])\n",
        "img = mpimg.imread('./save_graph/breakout_deep_qn.png')\n",
        "pylab.imshow(img)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fc30aa05a60>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x800 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NZGS-7t64YGf"
      },
      "source": [
        "## Training data for DDQN "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QTJFYbnL4YGf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 653
        },
        "outputId": "9b4fbc48-ccb4-4aa6-84d5-8a98464f91e8"
      },
      "source": [
        "import matplotlib.image as mpimg\n",
        "fig = plt.figure(figsize=(8,8))\n",
        "ax = fig.add_axes([0, 0, 1, 1], frameon=False)\n",
        "ax.margins(0)\n",
        "ax.set_xticks([])\n",
        "ax.set_yticks([])\n",
        "img = mpimg.imread('./save_graph/breakout_double_dqn.png')\n",
        "pylab.imshow(img)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fc30afdefd0>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x800 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mHzHU1nF2Jpr",
        "tags": [
          "noshow"
        ]
      },
      "source": [
        "# Visualize Agent Performance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pDjjzaiB2Jpr",
        "tags": [
          "noshow"
        ]
      },
      "source": [
        "BE AWARE THIS CODE BELOW MAY CRASH THE KERNEL IF YOU RUN THE SAME CELL TWICE.\n",
        "\n",
        "Please save your model before running this portion of the code."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zcLNUIvu2Jpr",
        "tags": [
          "noshow"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2e2090e-7c87-48c9-d8af-475ed209b77a"
      },
      "source": [
        "if True:\n",
        "  torch.save(agent.policy_net.state_dict(), f\"./save_model/breakout_{model_type}_latest.pth\")"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iyBhHGeR2Jps",
        "tags": [
          "noshow"
        ]
      },
      "source": [
        "from gym.wrappers import Monitor\n",
        "import glob\n",
        "import io\n",
        "import base64\n",
        "\n",
        "from IPython.display import HTML\n",
        "from IPython import display as ipythondisplay\n",
        "\n",
        "from pyvirtualdisplay import Display\n",
        "\n",
        "# Displaying the game live\n",
        "def show_state(env, step=0, info=\"\"):\n",
        "    plt.figure(3)\n",
        "    plt.clf()\n",
        "    plt.imshow(env.render(mode='rgb_array'))\n",
        "    plt.title(\"%s | Step: %d %s\" % (\"Agent Playing\",step, info))\n",
        "    plt.axis('off')\n",
        "\n",
        "    ipythondisplay.clear_output(wait=True)\n",
        "    ipythondisplay.display(plt.gcf())\n",
        "    \n",
        "# Recording the game and replaying the game afterwards\n",
        "def show_video():\n",
        "    mp4list = glob.glob('video/*.mp4')\n",
        "    if len(mp4list) > 0:\n",
        "        mp4 = mp4list[0]\n",
        "        video = io.open(mp4, 'r+b').read()\n",
        "        encoded = base64.b64encode(video)\n",
        "        ipythondisplay.display(HTML(data='''<video alt=\"test\" autoplay \n",
        "                loop controls style=\"height: 400px;\">\n",
        "                <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n",
        "             </video>'''.format(encoded.decode('ascii'))))\n",
        "    else: \n",
        "        print(\"Could not find video\")\n",
        "    \n",
        "\n",
        "def wrap_env(env):\n",
        "    env = Monitor(env, './video', force=True)\n",
        "    return env"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6nVgjfDp2Jps",
        "tags": [
          "noshow"
        ]
      },
      "source": [
        "display = Display(visible=0, size=(300, 200))\n",
        "display.start()\n",
        "\n",
        "# Load agent\n",
        "agent.load_policy_net(f\"./save_model/breakout_{model_type}_latest.pth\")\n",
        "agent.epsilon = 0.0 # Set agent to only exploit the best action\n",
        "\n",
        "env = gym.make('BreakoutDeterministic-v4')\n",
        "env = wrap_env(env)\n",
        "\n",
        "done = False\n",
        "score = 0\n",
        "step = 0\n",
        "state = env.reset()\n",
        "next_state = state\n",
        "life = number_lives\n",
        "history = np.zeros([5, 84, 84], dtype=np.uint8)\n",
        "get_init_state(history, state)\n",
        "\n",
        "while not done:\n",
        "    \n",
        "    # Render breakout\n",
        "    env.render()\n",
        "#     show_state(env,step) # uncommenting this provides another way to visualize the game\n",
        "\n",
        "    step += 1\n",
        "    frame += 1\n",
        "\n",
        "    # Perform a fire action if ball is no longer on screen\n",
        "    if step > 1 and len(np.unique(next_state[:189] == state[:189])) < 2:\n",
        "        action = 0\n",
        "    else:\n",
        "        action = agent.get_action(np.float32(history[:4, :, :]) / 255.)\n",
        "    state = next_state\n",
        "    \n",
        "    next_state, reward, done, info = env.step(action + 1)\n",
        "        \n",
        "    frame_next_state = get_frame(next_state)\n",
        "    history[4, :, :] = frame_next_state\n",
        "    terminal_state = check_live(life, info['ale.lives'])\n",
        "        \n",
        "    life = info['ale.lives']\n",
        "    r = np.clip(reward, -1, 1) \n",
        "    r = reward\n",
        "\n",
        "    # Store the transition in memory \n",
        "    agent.memory.push(deepcopy(frame_next_state), action, r, terminal_state)\n",
        "    # Start training after random sample generation\n",
        "    score += reward\n",
        "    \n",
        "    history[:4, :, :] = history[1:, :, :]\n",
        "env.close()\n",
        "show_video()\n",
        "display.stop()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6R_teeK_6Zq6"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}